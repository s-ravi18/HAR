{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-ravi18/HAR/blob/main/Verifying_Results_for_HAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X48xQ0G0cMPI",
        "outputId": "3ee3b136-e169-4747-9466-df6b7f103fa1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZlLqID4WwE5",
        "outputId": "10047db7-a8ae-41ab-8d31-b3bf6150777d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.9/dist-packages (1.1.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.4.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.9/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.9/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.9/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.0->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (1.0.7)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (5.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (4.39.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->catboost) (23.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly->catboost) (8.2.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.15.0)\n"
          ]
        }
      ],
      "source": [
        "##Basics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import regex as re\n",
        "import os\n",
        "import string\n",
        "import time\n",
        "import warnings\n",
        "import json\n",
        "from os import path\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "##ML scikit learn classes for data preprocessing:\n",
        "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "##ML scikit learn classes for model selection:  \n",
        "from xgboost import XGBClassifier\n",
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "##ML scikit learn classes for evaluating model:\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report,accuracy_score,make_scorer,confusion_matrix,precision_recall_fscore_support,roc_curve\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "## Deep Learning Libraries:\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model,Model\n",
        "from tensorflow.keras.layers import concatenate,Input,Dense,ReLU,BatchNormalization,Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "W_1Nykx7ZNEf"
      },
      "outputs": [],
      "source": [
        "## Setting the seed to allow reproducibility\n",
        "np.random.seed(31415)\n",
        "tf.random.set_seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i3PTcNx-ZWQ7"
      },
      "outputs": [],
      "source": [
        "### Label Encoding, Removing Zero variance Features and Scaling the test data::\n",
        "def initial(df):\n",
        "    \n",
        "    #### Label Encoding the Target Variable\n",
        "\n",
        "    X=df.drop([\"label\"],axis=1)\n",
        "    y=df[\"label\"]\n",
        "    if df.label.dtype==str:   ### Will apply label encoding if needed\n",
        "        le=LabelEncoder()\n",
        "        y=le.fit_transform(y)\n",
        "        y=pd.Series(y)\n",
        "\n",
        "    #### Removing Features having zero variance.\n",
        "\n",
        "    Var=X[X.columns].std()\n",
        "    col=Var[Var==0].index\n",
        "    X=X.drop(col,axis=1)\n",
        "    \n",
        "    return X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ho4sQ0K2ZNGa"
      },
      "outputs": [],
      "source": [
        "### For the best model using EMG and NEMG Features (EMG+NEMG Combined)\n",
        "# df_emg=pd.read_csv(\"/content/drive/MyDrive/HAR Datasets/EMG_ANOVA_200_features.csv\").rename({'0':'label'},axis=1)\n",
        "df_nemg=pd.read_csv(\"/content/drive/MyDrive/HAR Datasets/NEMG_ANOVA_200_features.csv\").rename({\"0\":\"label\"},axis=1)\n",
        "\n",
        "# temp=pd.DataFrame()\n",
        "# for i in range(26):\n",
        "#     n=df_nemg[df_nemg[\"label\"]==i].reset_index(drop=True)\n",
        "#     e=df_emg[df_emg[\"label\"]==i].reset_index(drop=True).drop([\"label\"],axis=1)[0:n.shape[0]]\n",
        "#     k=pd.concat([e,n],axis=1)\n",
        "#     temp=pd.concat([temp,k],axis=0)   \n",
        "\n",
        "X,y=initial(df_nemg) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0AxN4K9OZNJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c7c735-b8ab-41d1-bac3-ce8ac31f04ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((23680, 200), (23680,))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "X.shape,y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "g1iOfJHWBQog"
      },
      "outputs": [],
      "source": [
        "l1=list(df_nemg.columns[:-1])\n",
        "#l2=list(df_nemg.columns[:-1])\n",
        "#l1.extend(l2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JehIchMlCE0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d48d356-ccdc-4f49-b4c4-b5d69ad2c610"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(l1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9fBzvluLZNK0"
      },
      "outputs": [],
      "source": [
        "## Splitting the data:\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y,test_size=0.15, random_state=2)\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_train=pd.DataFrame(X_train,columns=l1)\n",
        "X_test=sc.transform(X_test)\n",
        "X_test=pd.DataFrame(X_test,columns=l1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tats0D4DhbVU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JBEkq6LytRLh"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "    def __init__(self,number,l1,l2,l3,l4):\n",
        "        self.number=number\n",
        "        self.model = tf.keras.Sequential()\n",
        "        self.model.add(tf.keras.layers.InputLayer(input_shape=(200)))\n",
        "        self.model.add(tf.keras.layers.Normalization(axis=-1))\n",
        "        self.model.add(tf.keras.layers.Dense(units=l1,activation=None))   ###\n",
        "        self.model.add(tf.keras.layers.BatchNormalization())\n",
        "        self.model.add(tf.keras.layers.ReLU())\n",
        "        self.model.add(tf.keras.layers.Dropout(0.2))\n",
        "        self.model.add(tf.keras.layers.Dense(units=l2,activation=None))  ###\n",
        "        self.model.add(tf.keras.layers.BatchNormalization())\n",
        "        self.model.add(tf.keras.layers.ReLU())\n",
        "        self.model.add(tf.keras.layers.Dropout(0.2))\n",
        "        self.model.add(tf.keras.layers.Dense(units=l3,activation=None))  ###\n",
        "        self.model.add(tf.keras.layers.BatchNormalization())\n",
        "        self.model.add(tf.keras.layers.ReLU())\n",
        "        self.model.add(tf.keras.layers.Dropout(0.2))\n",
        "        self.model.add(tf.keras.layers.Dense(units=l4,activation=None))  ###\n",
        "        self.model.add(tf.keras.layers.BatchNormalization())\n",
        "        self.model.add(tf.keras.layers.ReLU())\n",
        "        self.model.add(tf.keras.layers.Dropout(0.2))\n",
        "        #self.model.add(tf.keras.layers.Dropout(0.3))\n",
        "        self.model.add(tf.keras.layers.Dense(units=26,activation=\"softmax\"))\n",
        "        self.model.compile(optimizer=\"adam\",loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=\"accuracy\")\n",
        "    \n",
        "    def funct_fit(self,path,X_train,X_test,y_train,y_test,count,n_split):\n",
        "        self.model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=50,batch_size=50)\n",
        "        if count==n_split:\n",
        "            self.model.save(f\"{path}/model_{self.number}_deep.h5\")\n",
        "        return self.model.history.history[\"accuracy\"],self.model.history.history[\"val_accuracy\"],self.model.history.history[\"loss\"],self.model.history.history[\"val_loss\"] \n",
        "\n",
        "def funct_avg(d):\n",
        "    temp={}\n",
        "    for i,j in d.items():\n",
        "        temp[i]=np.mean(j)\n",
        "        \n",
        "    return temp\n",
        "\n",
        "def lc(path,m,acc,val_acc,loss,val_loss):\n",
        "  if os.path.exists(f\"{path}/LC\")==False:\n",
        "    os.mkdir(f\"{path}/LC\")\n",
        "  fig,ax=plt.subplots(1,2,figsize=(15,7))\n",
        "  ax[0].plot(acc,c= 'b',label=\"train_accuracy\")\n",
        "  ax[0].plot(val_acc,c= 'r',label=\"val_accuracy\")\n",
        "  ax[0].set_xlabel(\"Number of Epochs\")\n",
        "  ax[0].set_ylabel(\"Accuracy\")\n",
        "  ax[0].legend()\n",
        "\n",
        "  ax[1].plot(loss,c= 'b',label=\"train_loss\")\n",
        "  ax[1].plot(val_loss,c= 'r',label=\"val_loss\")\n",
        "  ax[1].set_xlabel(\"Number of Epochs\")\n",
        "  ax[1].set_ylabel(\"Loss\")\n",
        "  ax[1].legend()\n",
        "\n",
        "  fig.savefig(f'{path}/LC/Learning Curve_{m}.png')\n",
        "\n",
        "### cross validation:\n",
        "def funct_cv(path,m,n_split,X,y,l1,l2,l3,l4,final_result):\n",
        "    dic_results={\"accuracy\":[],\"val_accuracy\":[]}\n",
        "    n_split=n_split\n",
        "    count=0\n",
        "    for index,(train_index,test_index) in enumerate(StratifiedKFold(n_split).split(X,y)):\n",
        "        X_train,X_test=X[train_index],X[test_index]\n",
        "        y_train,y_test=y[train_index],y[test_index]\n",
        "\n",
        "        model=Model(m,l1,l2,l3,l4)   ### creating the model object \n",
        "        count=count+1\n",
        "        acc,val_acc,loss,val_loss=model.funct_fit(path,X_train,X_test, y_train,y_test,count,n_split) \n",
        "        if index==4:\n",
        "          lc(path,m,acc,val_acc,loss,val_loss)\n",
        "\n",
        "        dic_results[\"accuracy\"].append(np.mean(acc))\n",
        "        dic_results[\"val_accuracy\"].append(np.mean(val_acc))\n",
        "\n",
        "    dic_results=funct_avg(dic_results)\n",
        "\n",
        "    final_result[m]=dic_results\n",
        "    return final_result\n",
        "\n",
        "# final_result={}\n",
        "# funct_cv(1,5,X_train.values,y_train.values,140,120,80,70)\n",
        "# funct_cv(2,5,X_train.values,y_train.values,180,160,100,90)\n",
        "# funct_cv(3,5,X_train.values,y_train.values,320,250,200,150)\n",
        "\n",
        "# with open('/content/drive/MyDrive/HAR Results/IMU/accuracy_results_StratifiedCV_deep.json', 'w') as fp:\n",
        "#     json.dump(final_result, fp,  indent=4) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "r9_4sBNkxFYq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6sY4EJwukFL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716134bf-1a81-4355-e222-8c396267d23c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "111/111 [==============================] - 0s 2ms/step\n",
            "Model Accuracy: 0.117399\n",
            "111/111 [==============================] - 0s 2ms/step\n",
            "Model Accuracy: 0.093750\n",
            "111/111 [==============================] - 0s 2ms/step\n",
            "Model Accuracy: 0.087556\n"
          ]
        }
      ],
      "source": [
        "#### Loading other models:\n",
        "def funct_load(path,number):\n",
        "    allmodels=[]\n",
        "    for i in range(1,number+1):\n",
        "        # load model from file\n",
        "        model = load_model(f'{path}/model_{i}_deep.h5')\n",
        "        with open(f'{path}/base_model_{i}_summary.txt', 'w') as f:  ### Getting the output of the model configuration.\n",
        "          with redirect_stdout(f):\n",
        "            model.summary()\n",
        "        # add to list of members\n",
        "        allmodels.append(model)\n",
        "    return allmodels\n",
        "            \n",
        "#funct_load(3)    \n",
        "\n",
        "# create stacked model input dataset as outputs from the individual ensemble models\n",
        "def stacked_dataset(allmodels, X_test):\n",
        "    stackX = None\n",
        "    for model in allmodels:\n",
        "        # make prediction\n",
        "        yhat = model.predict(X_test, verbose=0)\n",
        "        # stack predictions into [rows, members, class]\n",
        "        if stackX is None:\n",
        "            stackX = yhat\n",
        "        else:\n",
        "            stackX = np.dstack((stackX, yhat))\n",
        "    print(stackX)\n",
        "    # flatten predictions to [rows, members x class]\n",
        "    stackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
        "    return stackX\n",
        "\n",
        "#stackedX = stacked_dataset(allmodels, X_test)\n",
        "\n",
        "# results={}\n",
        "\n",
        "# evaluate standalone models on test dataset\n",
        "for model in allmodels:\n",
        "    y_hat=model.predict(X_test)\n",
        "    y_hat=np.argmax(y_hat,axis=1)\n",
        "    acc = accuracy_score(y_test, y_hat)\n",
        "    print('Model Accuracy: %.6f' % acc)\n",
        "\n",
        "\n",
        "def funct_report_csv(y,y_hat):\n",
        "    clf_rep = precision_recall_fscore_support(y, y_hat)\n",
        "    out_dict = {\n",
        "                 \"precision\" :clf_rep[0].round(2)\n",
        "                ,\"recall\" : clf_rep[1].round(2)\n",
        "                ,\"f1-score\" : clf_rep[2].round(2)\n",
        "                ,\"support\" : clf_rep[3]\n",
        "                }\n",
        "    out_df = pd.DataFrame(out_dict)\n",
        "    avg_tot = (out_df.apply(lambda x: round(x.mean(), 2) if x.name!=\"support\" else  round(x.sum(), 2)).to_frame().T)\n",
        "    avg_tot.index = [\"avg/total\"]\n",
        "    out_df = out_df.append(avg_tot)\n",
        "    return out_df\n",
        "\n",
        "def classification_report_with_accuracy_score(y, y_hat,model_name,path):\n",
        "    if os.path.exists(f\"{path}/CR\")==False:\n",
        "      os.mkdir(f\"{path}/CR\")\n",
        "    if os.path.exists(f\"{path}/CM\")==False:\n",
        "      os.mkdir(f\"{path}/CM\")\n",
        "    #report=classification_report(y, y_hat,output_dict=True) # print classification report\n",
        "    report=funct_report_csv(y, y_hat) # print classification report\n",
        "    report.to_csv(f\"{path}/CR/Classification_Report_{model_name}.csv\",index=False)\n",
        "\n",
        "    cm=confusion_matrix(y,y_hat)\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.rc(\"font\",size=10)\n",
        "    sns.heatmap(cm,annot=True,fmt=\".2f\",cmap=\"viridis\")\n",
        "    plt.savefig(f\"{path}/CM/Confusion_Matrix_{model_name}_simple.png\")\n",
        "\n",
        "    cm_1 = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # For normalising the Matrix for better visualisation.\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.rc(\"font\",size=10)\n",
        "    sns.heatmap(cm_1,annot=True,fmt=\".2f\",cmap=\"viridis\")\n",
        "    plt.savefig(f\"{path}/CM/Confusion_Matrix_{model_name}_axis=1.png\")\n",
        "    \n",
        "    return accuracy_score(y, y_hat) # return accuracy score\n",
        "\n",
        "    \n",
        "def stacked_model_test(path,allmodels,X,y):\n",
        "    results={}\n",
        "    # dictionary of all models\n",
        "    sample={\"Naive Bayes\":GaussianNB(),\"XGB\":XGBClassifier(),\"LGBM\":LGBMClassifier(),\"RandomForest\":RandomForestClassifier(),\"LR\":LogisticRegression(),\"CatBoost\":CatBoostClassifier(),\"Naive Bayes\":GaussianNB(),\"SVC\":SVC(),\"KNN_3\":KNeighborsClassifier(n_neighbors=3),\"KNN_5\":KNeighborsClassifier(n_neighbors=5)}\n",
        "    # create dataset using ensemble\n",
        "    stackedX = stacked_dataset(allmodels, X)\n",
        "    \n",
        "    for i,j in sample.items():\n",
        "        arg={\"model_name\":i,\"path\":path}\n",
        "        sc=make_scorer(classification_report_with_accuracy_score,**arg)\n",
        "        score_=cross_val_score(j,stackedX,y,cv=5,scoring=sc)\n",
        "        acc = score_.mean()\n",
        "       \n",
        "        results[i]=round(acc,5)\n",
        "    return results           \n",
        "\n",
        "# stacked_model_test(allmodels,X_test,y_test)\n",
        "# #### To store the results in the form of json that is prettified:\n",
        "# with open('/content/drive/MyDrive/HAR Results/IMU/accuracy_results_final_stacked_random-sampling.json', 'w') as fp:\n",
        "#     json.dump(results, fp,  indent=4)     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "W4kFueOlYQi-"
      },
      "outputs": [],
      "source": [
        "## Function for ROC and Shap FI:\n",
        "def roc(path,X_train,X_test,y_train,y_test,model_name,model):\n",
        "  if os.path.exists(f\"{path}/ROC\")==False:\n",
        "    os.mkdir(f\"{path}/ROC\")\n",
        "  plt.figure(figsize=(10,10))\n",
        "  plt.title(\"ROC Curve and AUC\", fontsize=18)\n",
        "  plt.xlabel(\"False Positive Rate\", fontsize=16)\n",
        "  plt.ylabel(\"True Positive Rate\", fontsize=16)\n",
        "  visualizer = RadViz(size=(700,700))\n",
        "  model = wrap(model)\n",
        "  visualizer = ROCAUC(model)\n",
        "\n",
        "  visualizer.fit(X_train, y_train)        # Fit the training data to the visualizer\n",
        "  visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
        "  visualizer.show(outpath=f\"{path}/ROC/ROC_{model_name}.png\")\n",
        "\n",
        "def stacked_model_test(path,allmodels,X,y):\n",
        "    # dictionary of all models\n",
        "    sample={\"Naive Bayes\":GaussianNB(),\"XGB\":XGBClassifier(),\"LGBM\":LGBMClassifier(),\"RandomForest\":RandomForestClassifier(),\"LR\":LogisticRegression(),\"CatBoost\":CatBoostClassifier(),\"Naive Bayes\":GaussianNB(),\"SVC\":SVC(),\"KNN_3\":KNeighborsClassifier(n_neighbors=3),\"KNN_5\":KNeighborsClassifier(n_neighbors=5)}\n",
        "    # create dataset using ensemble\n",
        "    stackedX = stacked_dataset(allmodels, X)\n",
        "    \n",
        "    X_train,X_test,y_train,y_test=train_test_split(stackedX,y,stratify=y)\n",
        "    for i,j in sample.items():      \n",
        "      arg={\"model_name\":i,\"model\":j}\n",
        "      try:\n",
        "        roc(path,X_train,X_test,y_train,y_test,**arg)  \n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        continue\n",
        "\n",
        "#stacked_model_test(allmodels,X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ME-uxu-qYh80"
      },
      "outputs": [],
      "source": [
        "## For Shap Visualisation and Top Features\n",
        "\n",
        "def shap_fe(path,df,X,y,model_name,model):\n",
        "  # compute SHAP values\n",
        "  model.fit(X,y)\n",
        "\n",
        "  if os.path.exists(f\"{path}/Shap\")==False:\n",
        "    os.mkdir(f\"{path}/Shap\")\n",
        "\n",
        "  explainer = shap.TreeExplainer(model)\n",
        "  shap_values = explainer.shap_values(X)\n",
        "\n",
        "  shap.summary_plot(shap_values, X, class_names= [i for i in range(26)], feature_names = df.columns,show=False)\n",
        "  plt.savefig(f\"{path}/Shap/Shap_Feature_Plot_{model_name}.png\")\n",
        "\n",
        "  vals= np.abs(shap_values[1]).mean(0)\n",
        "  df_feature_importance=pd.DataFrame(np.concatenate([np.array(df.columns).reshape(-1,1),vals.reshape(-1,1)],axis=1),columns=[\"Feature\",\"Shap_Scores\"])\n",
        "  df_feature_importance = df_feature_importance.sort_values('Shap_Scores',ascending=False)\n",
        "  df_feature_importance.reset_index(drop=True,inplace=True)\n",
        "  df_feature_importance.to_csv(f\"{path}/Shap/Feature_scores_{model_name}.csv\")\n",
        "\n",
        "# sample={\"XGB\":XGBClassifier()} #,\"LGBM\":LGBMClassifier(),\"RandomForest\":RandomForestClassifier(),\"LR\":LogisticRegression(),\"CatBoost\":CatBoostClassifier(),\"Naive Bayes\":GaussianNB(),\"SVC\":SVC(),\"KNN_3\":KNeighborsClassifier(n_neighbors=3),\"KNN_5\":KNeighborsClassifier(n_neighbors=5)}  \n",
        "# for i,j in sample.items():\n",
        "#   try:\n",
        "#     shap_fe(df_nemg.iloc[:,:-1],X_train,y_train,i,j)\n",
        "#   except Exception as e:\n",
        "#     print(e)\n",
        "#     continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "hMHK87fzodQ5"
      },
      "outputs": [],
      "source": [
        "def master_fn(data,path):\n",
        "  if os.path.exists(f\"{path}\")==False:\n",
        "    os.mkdir(f\"{path}\")\n",
        "  ## Reading the data::\n",
        "  if data==\"EMG\":\n",
        "    df=pd.read_csv(\"/content/drive/MyDrive/HAR Datasets/EMG_ANOVA_200_features.csv\").rename({'0':'label'},axis=1)\n",
        "  elif data==\"IMU\":\n",
        "    df=pd.read_csv(\"/content/drive/MyDrive/HAR Datasets/Combined Results/NEMG_ANOVA_200_features.csv\").rename({\"0\":\"label\"},axis=1)\n",
        "  elif data==\"Combined\":\n",
        "    df_emg=pd.read_csv(\"/content/drive/MyDrive/HAR Datasets/EMG_ANOVA_200_features.csv\").rename({'0':'label'},axis=1)\n",
        "    df_nemg=pd.read_csv(\"/content/drive/MyDrive/HAR Datasets/Combined Results/NEMG_ANOVA_200_features.csv\").rename({\"0\":\"label\"},axis=1)\n",
        "    df=pd.DataFrame()\n",
        "    for i in range(26):\n",
        "        n=df_nemg[df_nemg[\"label\"]==i].reset_index(drop=True)\n",
        "        e=df_emg[df_emg[\"label\"]==i].reset_index(drop=True).drop([\"label\"],axis=1)[0:n.shape[0]]\n",
        "        k=pd.concat([e,n],axis=1)\n",
        "        df=pd.concat([df,k],axis=0)   \n",
        "\n",
        "  ## Label Encoding->Removing Zero Variance Features->Scaling the test data::\n",
        "  X,y=initial(df)\n",
        "\n",
        "  ## Splitting the data:\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y,test_size=0.15, random_state=2)\n",
        "  sc=StandardScaler()\n",
        "  X_train=sc.fit_transform(X_train)\n",
        "  X_train=pd.DataFrame(X_train,columns=list(df.columns[:-1]))\n",
        "  X_test=sc.transform(X_test)\n",
        "  X_test=pd.DataFrame(X_test,columns=list(df.columns[:-1]))\n",
        "\n",
        "  ## Creating and training the models:\n",
        "  final_result={}\n",
        "  final_result=funct_cv(path,1,5,X_train.values,y_train.values,140,120,80,70,final_result)\n",
        "  final_result=funct_cv(path,2,5,X_train.values,y_train.values,180,160,100,90,final_result)\n",
        "  final_result=funct_cv(path,3,5,X_train.values,y_train.values,320,250,200,150,final_result)\n",
        "\n",
        "  with open(f'{path}/accuracy_results_StratifiedCV_deep.json', 'w') as fp:\n",
        "      json.dump(final_result, fp,  indent=4) \n",
        "\n",
        "  ## Loading the models:\n",
        "  allmodels=funct_load(path,3)\n",
        "\n",
        "  ## \n",
        "  results=stacked_model_test(path,allmodels,X_test,y_test)\n",
        "  ## To store the results in the form of json that is prettified:\n",
        "  with open(f'{path}/accuracy_results_final_stacked_random-sampling.json', 'w') as fp:\n",
        "      json.dump(results, fp,  indent=4)\n",
        "\n",
        "  ## ROC and Shap:\n",
        "  stacked_model_test(path,allmodels,X_test,y_test)    \n",
        "\n",
        "  sample={\"XGB\":XGBClassifier()} #,\"LGBM\":LGBMClassifier(),\"RandomForest\":RandomForestClassifier(),\"LR\":LogisticRegression(),\"CatBoost\":CatBoostClassifier(),\"Naive Bayes\":GaussianNB(),\"SVC\":SVC(),\"KNN_3\":KNeighborsClassifier(n_neighbors=3),\"KNN_5\":KNeighborsClassifier(n_neighbors=5)}  \n",
        "  for i,j in sample.items():\n",
        "    try:\n",
        "      shap_fe(path,df_nemg.iloc[:,:-1],X_train,y_train,i,j)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR4vqOVHQ0Mt",
        "outputId": "2ca2cf23-3d6d-45ae-9378-e4d4725e4eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[6.38044151e-09 1.60730151e-10 2.52900253e-11]\n",
            "  [5.08783899e-07 7.18212095e-06 1.83324516e-07]\n",
            "  [4.57483196e-07 3.77108393e-07 1.16107287e-07]\n",
            "  ...\n",
            "  [1.81605742e-06 1.29816456e-07 7.60002123e-08]\n",
            "  [1.13593260e-05 7.93476090e-07 9.03390264e-06]\n",
            "  [2.50931237e-07 3.61808858e-08 2.53839838e-10]]\n",
            "\n",
            " [[1.35215515e-12 8.03434576e-12 2.80434313e-13]\n",
            "  [2.47548093e-11 3.07072319e-11 8.11577971e-10]\n",
            "  [1.88357945e-12 1.02127820e-10 3.72104847e-11]\n",
            "  ...\n",
            "  [6.18643027e-12 1.85771589e-11 1.27061209e-11]\n",
            "  [9.68054366e-08 7.90411505e-08 3.06754044e-09]\n",
            "  [5.43410206e-13 2.61286288e-11 2.46139979e-12]]\n",
            "\n",
            " [[3.84785342e-10 9.59314295e-11 3.73715989e-12]\n",
            "  [9.99997735e-01 9.99999166e-01 9.99976516e-01]\n",
            "  [1.40165230e-06 5.58949750e-07 1.52421126e-05]\n",
            "  ...\n",
            "  [2.68460559e-10 8.72680834e-12 8.90380894e-11]\n",
            "  [3.60979406e-08 3.95739032e-11 1.05032434e-10]\n",
            "  [2.31408279e-08 8.89096885e-09 3.52632732e-08]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[6.83713433e-11 1.96332395e-11 2.20559289e-13]\n",
            "  [9.99999642e-01 1.00000000e+00 9.99998689e-01]\n",
            "  [2.23245607e-07 5.35445395e-08 7.01000886e-07]\n",
            "  ...\n",
            "  [8.05712788e-11 5.32549699e-12 5.28088250e-12]\n",
            "  [7.29327443e-09 4.12602556e-11 1.26681790e-11]\n",
            "  [5.40617018e-09 4.77865258e-09 4.38087699e-09]]\n",
            "\n",
            " [[1.40217526e-06 1.09516755e-07 2.74138370e-06]\n",
            "  [1.26051259e-06 2.31595254e-09 5.07397180e-11]\n",
            "  [1.40759809e-07 1.68450878e-11 7.30949523e-09]\n",
            "  ...\n",
            "  [7.57102114e-08 6.99371441e-08 3.07043072e-11]\n",
            "  [2.52850463e-10 1.55983543e-07 8.01448057e-12]\n",
            "  [3.90542596e-07 1.01191766e-08 2.28032024e-10]]\n",
            "\n",
            " [[5.48561088e-13 1.17822297e-11 4.96656481e-14]\n",
            "  [5.71526819e-11 8.24768801e-13 1.31629801e-13]\n",
            "  [4.01794646e-13 2.18525325e-13 2.65951100e-14]\n",
            "  ...\n",
            "  [4.58140036e-12 3.07972363e-11 2.66623459e-11]\n",
            "  [1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            "  [4.45256462e-12 1.65607586e-13 1.83516431e-11]]]\n",
            "Learning rate set to 0.083771\n",
            "0:\tlearn: 2.7975752\ttotal: 629ms\tremaining: 10m 28s\n",
            "1:\tlearn: 2.4361990\ttotal: 1.12s\tremaining: 9m 19s\n",
            "2:\tlearn: 2.1999747\ttotal: 1.66s\tremaining: 9m 10s\n",
            "3:\tlearn: 1.9644818\ttotal: 2.23s\tremaining: 9m 16s\n",
            "4:\tlearn: 1.7961741\ttotal: 2.78s\tremaining: 9m 13s\n",
            "5:\tlearn: 1.6848246\ttotal: 3.29s\tremaining: 9m 5s\n",
            "6:\tlearn: 1.5896134\ttotal: 3.79s\tremaining: 8m 57s\n",
            "7:\tlearn: 1.4776505\ttotal: 4.1s\tremaining: 8m 28s\n",
            "8:\tlearn: 1.3858873\ttotal: 4.4s\tremaining: 8m 4s\n",
            "9:\tlearn: 1.2670723\ttotal: 4.72s\tremaining: 7m 46s\n",
            "10:\tlearn: 1.1673355\ttotal: 5.03s\tremaining: 7m 31s\n",
            "11:\tlearn: 1.0860575\ttotal: 5.34s\tremaining: 7m 19s\n",
            "12:\tlearn: 1.0173941\ttotal: 5.65s\tremaining: 7m 9s\n",
            "13:\tlearn: 0.9666287\ttotal: 5.97s\tremaining: 7m\n",
            "14:\tlearn: 0.9038548\ttotal: 6.29s\tremaining: 6m 53s\n",
            "15:\tlearn: 0.8662800\ttotal: 6.6s\tremaining: 6m 46s\n",
            "16:\tlearn: 0.8299396\ttotal: 6.91s\tremaining: 6m 39s\n",
            "17:\tlearn: 0.7929600\ttotal: 7.22s\tremaining: 6m 34s\n",
            "18:\tlearn: 0.7667691\ttotal: 7.54s\tremaining: 6m 29s\n",
            "19:\tlearn: 0.7203246\ttotal: 7.86s\tremaining: 6m 25s\n",
            "20:\tlearn: 0.6834942\ttotal: 8.17s\tremaining: 6m 20s\n",
            "21:\tlearn: 0.6499003\ttotal: 8.48s\tremaining: 6m 16s\n",
            "22:\tlearn: 0.6174263\ttotal: 8.79s\tremaining: 6m 13s\n",
            "23:\tlearn: 0.5949286\ttotal: 9.1s\tremaining: 6m 10s\n",
            "24:\tlearn: 0.5748785\ttotal: 9.4s\tremaining: 6m 6s\n",
            "25:\tlearn: 0.5442101\ttotal: 9.72s\tremaining: 6m 4s\n",
            "26:\tlearn: 0.5141553\ttotal: 10.1s\tremaining: 6m 2s\n",
            "27:\tlearn: 0.4903542\ttotal: 10.4s\tremaining: 6m\n",
            "28:\tlearn: 0.4674807\ttotal: 10.7s\tremaining: 5m 57s\n",
            "29:\tlearn: 0.4491355\ttotal: 11s\tremaining: 5m 55s\n",
            "30:\tlearn: 0.4302694\ttotal: 11.3s\tremaining: 5m 53s\n",
            "31:\tlearn: 0.4128719\ttotal: 11.6s\tremaining: 5m 51s\n",
            "32:\tlearn: 0.3997958\ttotal: 11.9s\tremaining: 5m 49s\n",
            "33:\tlearn: 0.3824405\ttotal: 12.2s\tremaining: 5m 47s\n",
            "34:\tlearn: 0.3670396\ttotal: 12.5s\tremaining: 5m 45s\n",
            "35:\tlearn: 0.3535507\ttotal: 12.8s\tremaining: 5m 43s\n",
            "36:\tlearn: 0.3407354\ttotal: 13.1s\tremaining: 5m 42s\n",
            "37:\tlearn: 0.3293722\ttotal: 13.4s\tremaining: 5m 40s\n",
            "38:\tlearn: 0.3214533\ttotal: 13.8s\tremaining: 5m 39s\n",
            "39:\tlearn: 0.3100927\ttotal: 14.3s\tremaining: 5m 43s\n",
            "40:\tlearn: 0.3007485\ttotal: 14.8s\tremaining: 5m 47s\n",
            "41:\tlearn: 0.2891676\ttotal: 15.3s\tremaining: 5m 49s\n",
            "42:\tlearn: 0.2795595\ttotal: 15.9s\tremaining: 5m 53s\n",
            "43:\tlearn: 0.2695195\ttotal: 16.4s\tremaining: 5m 57s\n",
            "44:\tlearn: 0.2614287\ttotal: 17s\tremaining: 6m 1s\n",
            "45:\tlearn: 0.2531552\ttotal: 17.6s\tremaining: 6m 4s\n",
            "46:\tlearn: 0.2452338\ttotal: 17.9s\tremaining: 6m 2s\n",
            "47:\tlearn: 0.2375656\ttotal: 18.2s\tremaining: 6m\n",
            "48:\tlearn: 0.2302126\ttotal: 18.5s\tremaining: 5m 58s\n",
            "49:\tlearn: 0.2234908\ttotal: 18.8s\tremaining: 5m 57s\n",
            "50:\tlearn: 0.2179272\ttotal: 19.1s\tremaining: 5m 55s\n",
            "51:\tlearn: 0.2121060\ttotal: 19.4s\tremaining: 5m 53s\n",
            "52:\tlearn: 0.2064483\ttotal: 19.7s\tremaining: 5m 52s\n",
            "53:\tlearn: 0.2009661\ttotal: 20s\tremaining: 5m 50s\n",
            "54:\tlearn: 0.1951430\ttotal: 20.3s\tremaining: 5m 49s\n",
            "55:\tlearn: 0.1907901\ttotal: 20.6s\tremaining: 5m 48s\n",
            "56:\tlearn: 0.1864163\ttotal: 21s\tremaining: 5m 46s\n",
            "57:\tlearn: 0.1820404\ttotal: 21.3s\tremaining: 5m 45s\n",
            "58:\tlearn: 0.1775735\ttotal: 21.6s\tremaining: 5m 44s\n",
            "59:\tlearn: 0.1734003\ttotal: 21.9s\tremaining: 5m 42s\n",
            "60:\tlearn: 0.1694671\ttotal: 22.2s\tremaining: 5m 41s\n",
            "61:\tlearn: 0.1655108\ttotal: 22.5s\tremaining: 5m 40s\n",
            "62:\tlearn: 0.1615302\ttotal: 22.8s\tremaining: 5m 39s\n",
            "63:\tlearn: 0.1578417\ttotal: 23.1s\tremaining: 5m 38s\n",
            "64:\tlearn: 0.1544459\ttotal: 23.4s\tremaining: 5m 37s\n",
            "65:\tlearn: 0.1515130\ttotal: 23.7s\tremaining: 5m 35s\n",
            "66:\tlearn: 0.1485873\ttotal: 24s\tremaining: 5m 34s\n",
            "67:\tlearn: 0.1450587\ttotal: 24.4s\tremaining: 5m 33s\n",
            "68:\tlearn: 0.1419220\ttotal: 24.7s\tremaining: 5m 32s\n",
            "69:\tlearn: 0.1385323\ttotal: 25s\tremaining: 5m 31s\n",
            "70:\tlearn: 0.1359819\ttotal: 25.3s\tremaining: 5m 30s\n",
            "71:\tlearn: 0.1329153\ttotal: 25.6s\tremaining: 5m 29s\n",
            "72:\tlearn: 0.1306892\ttotal: 25.9s\tremaining: 5m 28s\n",
            "73:\tlearn: 0.1284142\ttotal: 26.2s\tremaining: 5m 27s\n",
            "74:\tlearn: 0.1261011\ttotal: 26.5s\tremaining: 5m 27s\n",
            "75:\tlearn: 0.1237124\ttotal: 26.8s\tremaining: 5m 26s\n",
            "76:\tlearn: 0.1215499\ttotal: 27.1s\tremaining: 5m 25s\n",
            "77:\tlearn: 0.1193096\ttotal: 27.4s\tremaining: 5m 24s\n",
            "78:\tlearn: 0.1170328\ttotal: 27.9s\tremaining: 5m 25s\n",
            "79:\tlearn: 0.1148767\ttotal: 28.5s\tremaining: 5m 27s\n",
            "80:\tlearn: 0.1127253\ttotal: 29.1s\tremaining: 5m 29s\n",
            "81:\tlearn: 0.1105301\ttotal: 29.7s\tremaining: 5m 32s\n",
            "82:\tlearn: 0.1087216\ttotal: 30.3s\tremaining: 5m 34s\n",
            "83:\tlearn: 0.1071830\ttotal: 30.9s\tremaining: 5m 36s\n",
            "84:\tlearn: 0.1053708\ttotal: 31.3s\tremaining: 5m 37s\n",
            "85:\tlearn: 0.1039684\ttotal: 31.6s\tremaining: 5m 36s\n",
            "86:\tlearn: 0.1023789\ttotal: 31.9s\tremaining: 5m 35s\n",
            "87:\tlearn: 0.1005888\ttotal: 32.2s\tremaining: 5m 34s\n",
            "88:\tlearn: 0.0991452\ttotal: 32.6s\tremaining: 5m 33s\n",
            "89:\tlearn: 0.0978619\ttotal: 32.9s\tremaining: 5m 32s\n",
            "90:\tlearn: 0.0961552\ttotal: 33.2s\tremaining: 5m 31s\n",
            "91:\tlearn: 0.0949446\ttotal: 33.5s\tremaining: 5m 30s\n",
            "92:\tlearn: 0.0934164\ttotal: 33.8s\tremaining: 5m 29s\n",
            "93:\tlearn: 0.0919008\ttotal: 34.1s\tremaining: 5m 28s\n",
            "94:\tlearn: 0.0904567\ttotal: 34.4s\tremaining: 5m 27s\n",
            "95:\tlearn: 0.0891724\ttotal: 34.7s\tremaining: 5m 26s\n",
            "96:\tlearn: 0.0881614\ttotal: 35s\tremaining: 5m 26s\n",
            "97:\tlearn: 0.0865851\ttotal: 35.3s\tremaining: 5m 25s\n",
            "98:\tlearn: 0.0854588\ttotal: 35.7s\tremaining: 5m 24s\n",
            "99:\tlearn: 0.0842989\ttotal: 36s\tremaining: 5m 23s\n",
            "100:\tlearn: 0.0831751\ttotal: 36.3s\tremaining: 5m 22s\n",
            "101:\tlearn: 0.0820019\ttotal: 36.6s\tremaining: 5m 21s\n",
            "102:\tlearn: 0.0807595\ttotal: 36.9s\tremaining: 5m 21s\n",
            "103:\tlearn: 0.0797964\ttotal: 37.2s\tremaining: 5m 20s\n",
            "104:\tlearn: 0.0788129\ttotal: 37.5s\tremaining: 5m 19s\n",
            "105:\tlearn: 0.0778827\ttotal: 37.8s\tremaining: 5m 18s\n",
            "106:\tlearn: 0.0767079\ttotal: 38.1s\tremaining: 5m 18s\n",
            "107:\tlearn: 0.0756219\ttotal: 38.4s\tremaining: 5m 17s\n",
            "108:\tlearn: 0.0748222\ttotal: 38.7s\tremaining: 5m 16s\n",
            "109:\tlearn: 0.0738247\ttotal: 39s\tremaining: 5m 15s\n",
            "110:\tlearn: 0.0730602\ttotal: 39.3s\tremaining: 5m 15s\n",
            "111:\tlearn: 0.0721802\ttotal: 39.7s\tremaining: 5m 14s\n",
            "112:\tlearn: 0.0715843\ttotal: 40s\tremaining: 5m 13s\n",
            "113:\tlearn: 0.0708122\ttotal: 40.3s\tremaining: 5m 13s\n",
            "114:\tlearn: 0.0700421\ttotal: 40.6s\tremaining: 5m 12s\n",
            "115:\tlearn: 0.0695067\ttotal: 40.9s\tremaining: 5m 11s\n",
            "116:\tlearn: 0.0687595\ttotal: 41.2s\tremaining: 5m 11s\n",
            "117:\tlearn: 0.0679894\ttotal: 41.7s\tremaining: 5m 11s\n",
            "118:\tlearn: 0.0671856\ttotal: 42.2s\tremaining: 5m 12s\n",
            "119:\tlearn: 0.0664147\ttotal: 42.8s\tremaining: 5m 13s\n",
            "120:\tlearn: 0.0657150\ttotal: 43.4s\tremaining: 5m 15s\n",
            "121:\tlearn: 0.0650773\ttotal: 44s\tremaining: 5m 16s\n",
            "122:\tlearn: 0.0643725\ttotal: 44.5s\tremaining: 5m 17s\n",
            "123:\tlearn: 0.0639157\ttotal: 45.1s\tremaining: 5m 18s\n",
            "124:\tlearn: 0.0633102\ttotal: 45.4s\tremaining: 5m 17s\n",
            "125:\tlearn: 0.0626140\ttotal: 45.7s\tremaining: 5m 16s\n",
            "126:\tlearn: 0.0619167\ttotal: 46s\tremaining: 5m 16s\n",
            "127:\tlearn: 0.0613460\ttotal: 46.3s\tremaining: 5m 15s\n",
            "128:\tlearn: 0.0606984\ttotal: 46.6s\tremaining: 5m 14s\n",
            "129:\tlearn: 0.0600696\ttotal: 46.9s\tremaining: 5m 13s\n",
            "130:\tlearn: 0.0594475\ttotal: 47.2s\tremaining: 5m 13s\n",
            "131:\tlearn: 0.0586520\ttotal: 47.5s\tremaining: 5m 12s\n",
            "132:\tlearn: 0.0579834\ttotal: 47.9s\tremaining: 5m 12s\n",
            "133:\tlearn: 0.0575190\ttotal: 48.2s\tremaining: 5m 11s\n",
            "134:\tlearn: 0.0569191\ttotal: 48.5s\tremaining: 5m 10s\n",
            "135:\tlearn: 0.0563464\ttotal: 48.8s\tremaining: 5m 10s\n",
            "136:\tlearn: 0.0557497\ttotal: 49.1s\tremaining: 5m 9s\n",
            "137:\tlearn: 0.0552528\ttotal: 49.4s\tremaining: 5m 8s\n",
            "138:\tlearn: 0.0546749\ttotal: 49.7s\tremaining: 5m 7s\n",
            "139:\tlearn: 0.0542461\ttotal: 50s\tremaining: 5m 7s\n",
            "140:\tlearn: 0.0539036\ttotal: 50.4s\tremaining: 5m 6s\n",
            "141:\tlearn: 0.0535282\ttotal: 50.7s\tremaining: 5m 6s\n",
            "142:\tlearn: 0.0530897\ttotal: 51s\tremaining: 5m 5s\n",
            "143:\tlearn: 0.0525529\ttotal: 51.3s\tremaining: 5m 4s\n",
            "144:\tlearn: 0.0519893\ttotal: 51.6s\tremaining: 5m 4s\n",
            "145:\tlearn: 0.0516320\ttotal: 51.9s\tremaining: 5m 3s\n",
            "146:\tlearn: 0.0510430\ttotal: 52.2s\tremaining: 5m 3s\n",
            "147:\tlearn: 0.0506472\ttotal: 52.5s\tremaining: 5m 2s\n",
            "148:\tlearn: 0.0501783\ttotal: 52.8s\tremaining: 5m 1s\n",
            "149:\tlearn: 0.0497495\ttotal: 53.2s\tremaining: 5m 1s\n",
            "150:\tlearn: 0.0492512\ttotal: 53.5s\tremaining: 5m\n",
            "151:\tlearn: 0.0488119\ttotal: 53.8s\tremaining: 5m\n",
            "152:\tlearn: 0.0483924\ttotal: 54.1s\tremaining: 4m 59s\n",
            "153:\tlearn: 0.0478537\ttotal: 54.4s\tremaining: 4m 58s\n",
            "154:\tlearn: 0.0474615\ttotal: 54.7s\tremaining: 4m 58s\n",
            "155:\tlearn: 0.0470775\ttotal: 55s\tremaining: 4m 57s\n",
            "156:\tlearn: 0.0467003\ttotal: 55.5s\tremaining: 4m 57s\n",
            "157:\tlearn: 0.0463257\ttotal: 56s\tremaining: 4m 58s\n",
            "158:\tlearn: 0.0460986\ttotal: 57.2s\tremaining: 5m 2s\n",
            "159:\tlearn: 0.0458329\ttotal: 58.3s\tremaining: 5m 6s\n",
            "160:\tlearn: 0.0454581\ttotal: 58.9s\tremaining: 5m 6s\n",
            "161:\tlearn: 0.0450948\ttotal: 59.3s\tremaining: 5m 6s\n",
            "162:\tlearn: 0.0447690\ttotal: 59.6s\tremaining: 5m 5s\n",
            "163:\tlearn: 0.0444539\ttotal: 59.9s\tremaining: 5m 5s\n",
            "164:\tlearn: 0.0442390\ttotal: 1m\tremaining: 5m 4s\n",
            "165:\tlearn: 0.0440730\ttotal: 1m\tremaining: 5m 3s\n",
            "166:\tlearn: 0.0436110\ttotal: 1m\tremaining: 5m 3s\n",
            "167:\tlearn: 0.0432911\ttotal: 1m 1s\tremaining: 5m 2s\n",
            "168:\tlearn: 0.0430284\ttotal: 1m 1s\tremaining: 5m 1s\n",
            "169:\tlearn: 0.0427505\ttotal: 1m 1s\tremaining: 5m 1s\n",
            "170:\tlearn: 0.0423558\ttotal: 1m 2s\tremaining: 5m\n",
            "171:\tlearn: 0.0420685\ttotal: 1m 2s\tremaining: 5m\n",
            "172:\tlearn: 0.0417117\ttotal: 1m 2s\tremaining: 4m 59s\n",
            "173:\tlearn: 0.0413996\ttotal: 1m 2s\tremaining: 4m 58s\n",
            "174:\tlearn: 0.0411550\ttotal: 1m 3s\tremaining: 4m 58s\n",
            "175:\tlearn: 0.0407745\ttotal: 1m 3s\tremaining: 4m 57s\n",
            "176:\tlearn: 0.0404650\ttotal: 1m 3s\tremaining: 4m 57s\n",
            "177:\tlearn: 0.0401694\ttotal: 1m 4s\tremaining: 4m 56s\n",
            "178:\tlearn: 0.0399339\ttotal: 1m 4s\tremaining: 4m 55s\n",
            "179:\tlearn: 0.0397076\ttotal: 1m 4s\tremaining: 4m 55s\n",
            "180:\tlearn: 0.0393748\ttotal: 1m 5s\tremaining: 4m 54s\n",
            "181:\tlearn: 0.0391982\ttotal: 1m 5s\tremaining: 4m 54s\n",
            "182:\tlearn: 0.0389524\ttotal: 1m 5s\tremaining: 4m 53s\n",
            "183:\tlearn: 0.0387247\ttotal: 1m 6s\tremaining: 4m 52s\n",
            "184:\tlearn: 0.0383898\ttotal: 1m 6s\tremaining: 4m 52s\n",
            "185:\tlearn: 0.0381261\ttotal: 1m 6s\tremaining: 4m 51s\n",
            "186:\tlearn: 0.0378236\ttotal: 1m 6s\tremaining: 4m 51s\n",
            "187:\tlearn: 0.0375299\ttotal: 1m 7s\tremaining: 4m 50s\n",
            "188:\tlearn: 0.0372032\ttotal: 1m 7s\tremaining: 4m 50s\n",
            "189:\tlearn: 0.0369736\ttotal: 1m 7s\tremaining: 4m 49s\n",
            "190:\tlearn: 0.0367943\ttotal: 1m 8s\tremaining: 4m 48s\n",
            "191:\tlearn: 0.0365534\ttotal: 1m 8s\tremaining: 4m 48s\n",
            "192:\tlearn: 0.0363523\ttotal: 1m 8s\tremaining: 4m 47s\n",
            "193:\tlearn: 0.0360792\ttotal: 1m 9s\tremaining: 4m 47s\n",
            "194:\tlearn: 0.0358222\ttotal: 1m 9s\tremaining: 4m 47s\n",
            "195:\tlearn: 0.0356295\ttotal: 1m 10s\tremaining: 4m 48s\n",
            "196:\tlearn: 0.0353713\ttotal: 1m 10s\tremaining: 4m 49s\n",
            "197:\tlearn: 0.0350351\ttotal: 1m 11s\tremaining: 4m 49s\n",
            "198:\tlearn: 0.0347393\ttotal: 1m 12s\tremaining: 4m 49s\n",
            "199:\tlearn: 0.0345172\ttotal: 1m 12s\tremaining: 4m 50s\n",
            "200:\tlearn: 0.0342618\ttotal: 1m 13s\tremaining: 4m 50s\n",
            "201:\tlearn: 0.0340304\ttotal: 1m 13s\tremaining: 4m 49s\n",
            "202:\tlearn: 0.0338526\ttotal: 1m 13s\tremaining: 4m 49s\n",
            "203:\tlearn: 0.0335395\ttotal: 1m 13s\tremaining: 4m 48s\n",
            "204:\tlearn: 0.0332574\ttotal: 1m 14s\tremaining: 4m 48s\n",
            "205:\tlearn: 0.0330268\ttotal: 1m 14s\tremaining: 4m 47s\n",
            "206:\tlearn: 0.0328364\ttotal: 1m 14s\tremaining: 4m 46s\n",
            "207:\tlearn: 0.0326353\ttotal: 1m 15s\tremaining: 4m 46s\n",
            "208:\tlearn: 0.0324135\ttotal: 1m 15s\tremaining: 4m 45s\n",
            "209:\tlearn: 0.0321445\ttotal: 1m 15s\tremaining: 4m 45s\n",
            "210:\tlearn: 0.0319470\ttotal: 1m 16s\tremaining: 4m 44s\n",
            "211:\tlearn: 0.0317103\ttotal: 1m 16s\tremaining: 4m 44s\n",
            "212:\tlearn: 0.0314537\ttotal: 1m 16s\tremaining: 4m 43s\n",
            "213:\tlearn: 0.0312763\ttotal: 1m 17s\tremaining: 4m 42s\n",
            "214:\tlearn: 0.0310097\ttotal: 1m 17s\tremaining: 4m 42s\n",
            "215:\tlearn: 0.0308425\ttotal: 1m 17s\tremaining: 4m 41s\n",
            "216:\tlearn: 0.0307201\ttotal: 1m 17s\tremaining: 4m 41s\n",
            "217:\tlearn: 0.0306407\ttotal: 1m 18s\tremaining: 4m 40s\n",
            "218:\tlearn: 0.0304946\ttotal: 1m 18s\tremaining: 4m 40s\n",
            "219:\tlearn: 0.0303138\ttotal: 1m 18s\tremaining: 4m 39s\n",
            "220:\tlearn: 0.0300695\ttotal: 1m 19s\tremaining: 4m 39s\n",
            "221:\tlearn: 0.0298930\ttotal: 1m 19s\tremaining: 4m 38s\n",
            "222:\tlearn: 0.0297016\ttotal: 1m 19s\tremaining: 4m 38s\n",
            "223:\tlearn: 0.0294804\ttotal: 1m 20s\tremaining: 4m 37s\n",
            "224:\tlearn: 0.0292144\ttotal: 1m 20s\tremaining: 4m 37s\n",
            "225:\tlearn: 0.0290136\ttotal: 1m 21s\tremaining: 4m 38s\n",
            "226:\tlearn: 0.0288397\ttotal: 1m 21s\tremaining: 4m 38s\n",
            "227:\tlearn: 0.0287290\ttotal: 1m 22s\tremaining: 4m 39s\n",
            "228:\tlearn: 0.0285478\ttotal: 1m 23s\tremaining: 4m 39s\n",
            "229:\tlearn: 0.0283465\ttotal: 1m 23s\tremaining: 4m 39s\n",
            "230:\tlearn: 0.0281829\ttotal: 1m 24s\tremaining: 4m 40s\n",
            "231:\tlearn: 0.0280280\ttotal: 1m 24s\tremaining: 4m 40s\n",
            "232:\tlearn: 0.0279723\ttotal: 1m 25s\tremaining: 4m 40s\n",
            "233:\tlearn: 0.0277839\ttotal: 1m 25s\tremaining: 4m 41s\n",
            "234:\tlearn: 0.0276337\ttotal: 1m 26s\tremaining: 4m 41s\n",
            "235:\tlearn: 0.0274432\ttotal: 1m 27s\tremaining: 4m 41s\n",
            "236:\tlearn: 0.0272957\ttotal: 1m 27s\tremaining: 4m 41s\n",
            "237:\tlearn: 0.0271033\ttotal: 1m 27s\tremaining: 4m 41s\n",
            "238:\tlearn: 0.0269501\ttotal: 1m 28s\tremaining: 4m 40s\n",
            "239:\tlearn: 0.0268000\ttotal: 1m 28s\tremaining: 4m 40s\n",
            "240:\tlearn: 0.0266345\ttotal: 1m 28s\tremaining: 4m 39s\n",
            "241:\tlearn: 0.0264998\ttotal: 1m 29s\tremaining: 4m 39s\n",
            "242:\tlearn: 0.0263601\ttotal: 1m 29s\tremaining: 4m 38s\n",
            "243:\tlearn: 0.0262047\ttotal: 1m 29s\tremaining: 4m 37s\n",
            "244:\tlearn: 0.0260028\ttotal: 1m 29s\tremaining: 4m 37s\n",
            "245:\tlearn: 0.0258605\ttotal: 1m 30s\tremaining: 4m 36s\n",
            "246:\tlearn: 0.0257231\ttotal: 1m 30s\tremaining: 4m 36s\n",
            "247:\tlearn: 0.0255514\ttotal: 1m 30s\tremaining: 4m 35s\n",
            "248:\tlearn: 0.0253769\ttotal: 1m 31s\tremaining: 4m 35s\n",
            "249:\tlearn: 0.0252701\ttotal: 1m 31s\tremaining: 4m 34s\n",
            "250:\tlearn: 0.0251327\ttotal: 1m 31s\tremaining: 4m 34s\n",
            "251:\tlearn: 0.0249724\ttotal: 1m 32s\tremaining: 4m 33s\n",
            "252:\tlearn: 0.0248330\ttotal: 1m 32s\tremaining: 4m 33s\n",
            "253:\tlearn: 0.0246970\ttotal: 1m 32s\tremaining: 4m 32s\n",
            "254:\tlearn: 0.0246836\ttotal: 1m 33s\tremaining: 4m 32s\n",
            "255:\tlearn: 0.0245545\ttotal: 1m 33s\tremaining: 4m 31s\n",
            "256:\tlearn: 0.0244044\ttotal: 1m 33s\tremaining: 4m 31s\n",
            "257:\tlearn: 0.0243091\ttotal: 1m 34s\tremaining: 4m 30s\n",
            "258:\tlearn: 0.0241418\ttotal: 1m 34s\tremaining: 4m 30s\n",
            "259:\tlearn: 0.0239825\ttotal: 1m 34s\tremaining: 4m 29s\n",
            "260:\tlearn: 0.0239747\ttotal: 1m 35s\tremaining: 4m 28s\n",
            "261:\tlearn: 0.0238964\ttotal: 1m 35s\tremaining: 4m 28s\n",
            "262:\tlearn: 0.0237434\ttotal: 1m 35s\tremaining: 4m 27s\n",
            "263:\tlearn: 0.0236190\ttotal: 1m 35s\tremaining: 4m 27s\n",
            "264:\tlearn: 0.0234696\ttotal: 1m 36s\tremaining: 4m 26s\n",
            "265:\tlearn: 0.0233332\ttotal: 1m 36s\tremaining: 4m 26s\n",
            "266:\tlearn: 0.0231876\ttotal: 1m 36s\tremaining: 4m 25s\n",
            "267:\tlearn: 0.0230804\ttotal: 1m 37s\tremaining: 4m 25s\n",
            "268:\tlearn: 0.0229654\ttotal: 1m 37s\tremaining: 4m 24s\n",
            "269:\tlearn: 0.0228193\ttotal: 1m 38s\tremaining: 4m 25s\n",
            "270:\tlearn: 0.0227037\ttotal: 1m 38s\tremaining: 4m 25s\n",
            "271:\tlearn: 0.0226229\ttotal: 1m 39s\tremaining: 4m 25s\n",
            "272:\tlearn: 0.0224875\ttotal: 1m 39s\tremaining: 4m 25s\n",
            "273:\tlearn: 0.0223646\ttotal: 1m 40s\tremaining: 4m 27s\n",
            "274:\tlearn: 0.0222852\ttotal: 1m 41s\tremaining: 4m 28s\n",
            "275:\tlearn: 0.0221746\ttotal: 1m 42s\tremaining: 4m 28s\n",
            "276:\tlearn: 0.0220792\ttotal: 1m 43s\tremaining: 4m 29s\n",
            "277:\tlearn: 0.0219843\ttotal: 1m 43s\tremaining: 4m 30s\n",
            "278:\tlearn: 0.0218488\ttotal: 1m 44s\tremaining: 4m 31s\n",
            "279:\tlearn: 0.0217372\ttotal: 1m 45s\tremaining: 4m 32s\n",
            "280:\tlearn: 0.0216303\ttotal: 1m 46s\tremaining: 4m 32s\n",
            "281:\tlearn: 0.0214817\ttotal: 1m 47s\tremaining: 4m 33s\n",
            "282:\tlearn: 0.0213579\ttotal: 1m 48s\tremaining: 4m 34s\n",
            "283:\tlearn: 0.0212750\ttotal: 1m 49s\tremaining: 4m 34s\n",
            "284:\tlearn: 0.0211834\ttotal: 1m 49s\tremaining: 4m 34s\n",
            "285:\tlearn: 0.0210482\ttotal: 1m 49s\tremaining: 4m 34s\n",
            "286:\tlearn: 0.0209692\ttotal: 1m 50s\tremaining: 4m 34s\n",
            "287:\tlearn: 0.0208494\ttotal: 1m 51s\tremaining: 4m 34s\n",
            "288:\tlearn: 0.0207347\ttotal: 1m 51s\tremaining: 4m 34s\n",
            "289:\tlearn: 0.0206714\ttotal: 1m 52s\tremaining: 4m 35s\n",
            "290:\tlearn: 0.0205836\ttotal: 1m 54s\tremaining: 4m 38s\n",
            "291:\tlearn: 0.0204753\ttotal: 1m 55s\tremaining: 4m 39s\n",
            "292:\tlearn: 0.0204116\ttotal: 1m 55s\tremaining: 4m 39s\n",
            "293:\tlearn: 0.0203195\ttotal: 1m 56s\tremaining: 4m 38s\n",
            "294:\tlearn: 0.0202700\ttotal: 1m 56s\tremaining: 4m 38s\n",
            "295:\tlearn: 0.0202009\ttotal: 1m 56s\tremaining: 4m 37s\n",
            "296:\tlearn: 0.0201085\ttotal: 1m 57s\tremaining: 4m 37s\n",
            "297:\tlearn: 0.0200205\ttotal: 1m 57s\tremaining: 4m 36s\n",
            "298:\tlearn: 0.0199284\ttotal: 1m 57s\tremaining: 4m 35s\n",
            "299:\tlearn: 0.0198438\ttotal: 1m 58s\tremaining: 4m 35s\n",
            "300:\tlearn: 0.0197567\ttotal: 1m 58s\tremaining: 4m 34s\n",
            "301:\tlearn: 0.0196692\ttotal: 1m 58s\tremaining: 4m 34s\n",
            "302:\tlearn: 0.0195709\ttotal: 1m 58s\tremaining: 4m 33s\n",
            "303:\tlearn: 0.0194837\ttotal: 1m 59s\tremaining: 4m 33s\n",
            "304:\tlearn: 0.0193916\ttotal: 1m 59s\tremaining: 4m 32s\n",
            "305:\tlearn: 0.0192810\ttotal: 1m 59s\tremaining: 4m 31s\n",
            "306:\tlearn: 0.0191648\ttotal: 2m\tremaining: 4m 31s\n",
            "307:\tlearn: 0.0190947\ttotal: 2m\tremaining: 4m 30s\n",
            "308:\tlearn: 0.0189860\ttotal: 2m\tremaining: 4m 30s\n",
            "309:\tlearn: 0.0189063\ttotal: 2m 1s\tremaining: 4m 29s\n",
            "310:\tlearn: 0.0188204\ttotal: 2m 1s\tremaining: 4m 29s\n",
            "311:\tlearn: 0.0187392\ttotal: 2m 1s\tremaining: 4m 28s\n",
            "312:\tlearn: 0.0186783\ttotal: 2m 2s\tremaining: 4m 27s\n",
            "313:\tlearn: 0.0186113\ttotal: 2m 2s\tremaining: 4m 27s\n",
            "314:\tlearn: 0.0185341\ttotal: 2m 2s\tremaining: 4m 26s\n",
            "315:\tlearn: 0.0184428\ttotal: 2m 2s\tremaining: 4m 26s\n",
            "316:\tlearn: 0.0183357\ttotal: 2m 3s\tremaining: 4m 25s\n",
            "317:\tlearn: 0.0182634\ttotal: 2m 3s\tremaining: 4m 25s\n",
            "318:\tlearn: 0.0182050\ttotal: 2m 3s\tremaining: 4m 24s\n",
            "319:\tlearn: 0.0181244\ttotal: 2m 4s\tremaining: 4m 23s\n",
            "320:\tlearn: 0.0180676\ttotal: 2m 4s\tremaining: 4m 23s\n",
            "321:\tlearn: 0.0179672\ttotal: 2m 4s\tremaining: 4m 22s\n",
            "322:\tlearn: 0.0178702\ttotal: 2m 5s\tremaining: 4m 22s\n",
            "323:\tlearn: 0.0178035\ttotal: 2m 5s\tremaining: 4m 21s\n",
            "324:\tlearn: 0.0177048\ttotal: 2m 5s\tremaining: 4m 21s\n",
            "325:\tlearn: 0.0176203\ttotal: 2m 6s\tremaining: 4m 21s\n",
            "326:\tlearn: 0.0175411\ttotal: 2m 7s\tremaining: 4m 21s\n",
            "327:\tlearn: 0.0174707\ttotal: 2m 7s\tremaining: 4m 21s\n",
            "328:\tlearn: 0.0174060\ttotal: 2m 8s\tremaining: 4m 21s\n",
            "329:\tlearn: 0.0173534\ttotal: 2m 8s\tremaining: 4m 21s\n",
            "330:\tlearn: 0.0172801\ttotal: 2m 9s\tremaining: 4m 21s\n",
            "331:\tlearn: 0.0171875\ttotal: 2m 9s\tremaining: 4m 20s\n",
            "332:\tlearn: 0.0170762\ttotal: 2m 9s\tremaining: 4m 20s\n",
            "333:\tlearn: 0.0170100\ttotal: 2m 10s\tremaining: 4m 19s\n",
            "334:\tlearn: 0.0169417\ttotal: 2m 10s\tremaining: 4m 19s\n",
            "335:\tlearn: 0.0168721\ttotal: 2m 10s\tremaining: 4m 18s\n",
            "336:\tlearn: 0.0168043\ttotal: 2m 11s\tremaining: 4m 18s\n",
            "337:\tlearn: 0.0167159\ttotal: 2m 11s\tremaining: 4m 17s\n",
            "338:\tlearn: 0.0166440\ttotal: 2m 11s\tremaining: 4m 16s\n",
            "339:\tlearn: 0.0165689\ttotal: 2m 12s\tremaining: 4m 16s\n",
            "340:\tlearn: 0.0164882\ttotal: 2m 12s\tremaining: 4m 15s\n",
            "341:\tlearn: 0.0164108\ttotal: 2m 12s\tremaining: 4m 15s\n",
            "342:\tlearn: 0.0163427\ttotal: 2m 13s\tremaining: 4m 14s\n",
            "343:\tlearn: 0.0162796\ttotal: 2m 13s\tremaining: 4m 14s\n",
            "344:\tlearn: 0.0162100\ttotal: 2m 13s\tremaining: 4m 13s\n",
            "345:\tlearn: 0.0161427\ttotal: 2m 13s\tremaining: 4m 13s\n",
            "346:\tlearn: 0.0160934\ttotal: 2m 14s\tremaining: 4m 12s\n",
            "347:\tlearn: 0.0160244\ttotal: 2m 14s\tremaining: 4m 12s\n",
            "348:\tlearn: 0.0159648\ttotal: 2m 14s\tremaining: 4m 11s\n",
            "349:\tlearn: 0.0158942\ttotal: 2m 15s\tremaining: 4m 11s\n",
            "350:\tlearn: 0.0158312\ttotal: 2m 15s\tremaining: 4m 10s\n",
            "351:\tlearn: 0.0157723\ttotal: 2m 15s\tremaining: 4m 10s\n",
            "352:\tlearn: 0.0157067\ttotal: 2m 16s\tremaining: 4m 9s\n",
            "353:\tlearn: 0.0156257\ttotal: 2m 16s\tremaining: 4m 8s\n",
            "354:\tlearn: 0.0155705\ttotal: 2m 16s\tremaining: 4m 8s\n",
            "355:\tlearn: 0.0154893\ttotal: 2m 17s\tremaining: 4m 7s\n",
            "356:\tlearn: 0.0154300\ttotal: 2m 17s\tremaining: 4m 7s\n",
            "357:\tlearn: 0.0153681\ttotal: 2m 17s\tremaining: 4m 6s\n",
            "358:\tlearn: 0.0152954\ttotal: 2m 17s\tremaining: 4m 6s\n",
            "359:\tlearn: 0.0152435\ttotal: 2m 18s\tremaining: 4m 5s\n",
            "360:\tlearn: 0.0151860\ttotal: 2m 18s\tremaining: 4m 5s\n",
            "361:\tlearn: 0.0151207\ttotal: 2m 18s\tremaining: 4m 4s\n",
            "362:\tlearn: 0.0150529\ttotal: 2m 19s\tremaining: 4m 4s\n",
            "363:\tlearn: 0.0149777\ttotal: 2m 20s\tremaining: 4m 4s\n",
            "364:\tlearn: 0.0149228\ttotal: 2m 21s\tremaining: 4m 5s\n",
            "365:\tlearn: 0.0148541\ttotal: 2m 21s\tremaining: 4m 5s\n",
            "366:\tlearn: 0.0148033\ttotal: 2m 22s\tremaining: 4m 6s\n",
            "367:\tlearn: 0.0147483\ttotal: 2m 23s\tremaining: 4m 6s\n",
            "368:\tlearn: 0.0146915\ttotal: 2m 23s\tremaining: 4m 6s\n",
            "369:\tlearn: 0.0146352\ttotal: 2m 24s\tremaining: 4m 5s\n",
            "370:\tlearn: 0.0145758\ttotal: 2m 24s\tremaining: 4m 5s\n",
            "371:\tlearn: 0.0144989\ttotal: 2m 24s\tremaining: 4m 4s\n",
            "372:\tlearn: 0.0144408\ttotal: 2m 25s\tremaining: 4m 4s\n",
            "373:\tlearn: 0.0143821\ttotal: 2m 25s\tremaining: 4m 3s\n",
            "374:\tlearn: 0.0143212\ttotal: 2m 25s\tremaining: 4m 3s\n",
            "375:\tlearn: 0.0142692\ttotal: 2m 26s\tremaining: 4m 2s\n",
            "376:\tlearn: 0.0142536\ttotal: 2m 26s\tremaining: 4m 2s\n",
            "377:\tlearn: 0.0141823\ttotal: 2m 26s\tremaining: 4m 1s\n",
            "378:\tlearn: 0.0141355\ttotal: 2m 27s\tremaining: 4m 1s\n",
            "379:\tlearn: 0.0140793\ttotal: 2m 27s\tremaining: 4m\n",
            "380:\tlearn: 0.0140150\ttotal: 2m 27s\tremaining: 4m\n",
            "381:\tlearn: 0.0139702\ttotal: 2m 28s\tremaining: 3m 59s\n",
            "382:\tlearn: 0.0139325\ttotal: 2m 28s\tremaining: 3m 59s\n",
            "383:\tlearn: 0.0138680\ttotal: 2m 28s\tremaining: 3m 58s\n",
            "384:\tlearn: 0.0138008\ttotal: 2m 29s\tremaining: 3m 58s\n",
            "385:\tlearn: 0.0137451\ttotal: 2m 29s\tremaining: 3m 57s\n",
            "386:\tlearn: 0.0137093\ttotal: 2m 29s\tremaining: 3m 57s\n",
            "387:\tlearn: 0.0136551\ttotal: 2m 29s\tremaining: 3m 56s\n",
            "388:\tlearn: 0.0136420\ttotal: 2m 30s\tremaining: 3m 56s\n",
            "389:\tlearn: 0.0135961\ttotal: 2m 30s\tremaining: 3m 55s\n",
            "390:\tlearn: 0.0135406\ttotal: 2m 30s\tremaining: 3m 55s\n",
            "391:\tlearn: 0.0134950\ttotal: 2m 31s\tremaining: 3m 54s\n",
            "392:\tlearn: 0.0134510\ttotal: 2m 31s\tremaining: 3m 54s\n",
            "393:\tlearn: 0.0134250\ttotal: 2m 32s\tremaining: 3m 53s\n",
            "394:\tlearn: 0.0133854\ttotal: 2m 32s\tremaining: 3m 53s\n",
            "395:\tlearn: 0.0133440\ttotal: 2m 32s\tremaining: 3m 52s\n",
            "396:\tlearn: 0.0132953\ttotal: 2m 33s\tremaining: 3m 52s\n",
            "397:\tlearn: 0.0132482\ttotal: 2m 33s\tremaining: 3m 52s\n",
            "398:\tlearn: 0.0132050\ttotal: 2m 33s\tremaining: 3m 51s\n",
            "399:\tlearn: 0.0131565\ttotal: 2m 34s\tremaining: 3m 52s\n",
            "400:\tlearn: 0.0131207\ttotal: 2m 35s\tremaining: 3m 52s\n",
            "401:\tlearn: 0.0130785\ttotal: 2m 36s\tremaining: 3m 52s\n",
            "402:\tlearn: 0.0130199\ttotal: 2m 37s\tremaining: 3m 53s\n",
            "403:\tlearn: 0.0129630\ttotal: 2m 37s\tremaining: 3m 52s\n",
            "404:\tlearn: 0.0129139\ttotal: 2m 38s\tremaining: 3m 52s\n",
            "405:\tlearn: 0.0128699\ttotal: 2m 38s\tremaining: 3m 52s\n",
            "406:\tlearn: 0.0128306\ttotal: 2m 39s\tremaining: 3m 51s\n",
            "407:\tlearn: 0.0127810\ttotal: 2m 39s\tremaining: 3m 51s\n",
            "408:\tlearn: 0.0127357\ttotal: 2m 39s\tremaining: 3m 50s\n",
            "409:\tlearn: 0.0126839\ttotal: 2m 40s\tremaining: 3m 50s\n",
            "410:\tlearn: 0.0126516\ttotal: 2m 40s\tremaining: 3m 49s\n",
            "411:\tlearn: 0.0126058\ttotal: 2m 40s\tremaining: 3m 49s\n",
            "412:\tlearn: 0.0125552\ttotal: 2m 41s\tremaining: 3m 48s\n",
            "413:\tlearn: 0.0125152\ttotal: 2m 41s\tremaining: 3m 48s\n",
            "414:\tlearn: 0.0124818\ttotal: 2m 41s\tremaining: 3m 47s\n",
            "415:\tlearn: 0.0124319\ttotal: 2m 41s\tremaining: 3m 47s\n",
            "416:\tlearn: 0.0123946\ttotal: 2m 42s\tremaining: 3m 46s\n",
            "417:\tlearn: 0.0123507\ttotal: 2m 42s\tremaining: 3m 46s\n",
            "418:\tlearn: 0.0123162\ttotal: 2m 42s\tremaining: 3m 45s\n",
            "419:\tlearn: 0.0122679\ttotal: 2m 43s\tremaining: 3m 45s\n",
            "420:\tlearn: 0.0122311\ttotal: 2m 43s\tremaining: 3m 44s\n",
            "421:\tlearn: 0.0122156\ttotal: 2m 43s\tremaining: 3m 44s\n",
            "422:\tlearn: 0.0121821\ttotal: 2m 44s\tremaining: 3m 43s\n",
            "423:\tlearn: 0.0121413\ttotal: 2m 44s\tremaining: 3m 43s\n",
            "424:\tlearn: 0.0120915\ttotal: 2m 44s\tremaining: 3m 42s\n",
            "425:\tlearn: 0.0120505\ttotal: 2m 45s\tremaining: 3m 42s\n",
            "426:\tlearn: 0.0120044\ttotal: 2m 45s\tremaining: 3m 41s\n",
            "427:\tlearn: 0.0119626\ttotal: 2m 45s\tremaining: 3m 41s\n",
            "428:\tlearn: 0.0119360\ttotal: 2m 46s\tremaining: 3m 40s\n",
            "429:\tlearn: 0.0118885\ttotal: 2m 46s\tremaining: 3m 40s\n",
            "430:\tlearn: 0.0118441\ttotal: 2m 46s\tremaining: 3m 39s\n",
            "431:\tlearn: 0.0118099\ttotal: 2m 46s\tremaining: 3m 39s\n",
            "432:\tlearn: 0.0117768\ttotal: 2m 47s\tremaining: 3m 38s\n",
            "433:\tlearn: 0.0117429\ttotal: 2m 47s\tremaining: 3m 38s\n",
            "434:\tlearn: 0.0117065\ttotal: 2m 48s\tremaining: 3m 38s\n",
            "435:\tlearn: 0.0116591\ttotal: 2m 48s\tremaining: 3m 38s\n",
            "436:\tlearn: 0.0116119\ttotal: 2m 49s\tremaining: 3m 38s\n",
            "437:\tlearn: 0.0115697\ttotal: 2m 49s\tremaining: 3m 37s\n",
            "438:\tlearn: 0.0115189\ttotal: 2m 50s\tremaining: 3m 37s\n",
            "439:\tlearn: 0.0114843\ttotal: 2m 50s\tremaining: 3m 37s\n",
            "440:\tlearn: 0.0114328\ttotal: 2m 51s\tremaining: 3m 37s\n",
            "441:\tlearn: 0.0113950\ttotal: 2m 51s\tremaining: 3m 36s\n",
            "442:\tlearn: 0.0113553\ttotal: 2m 52s\tremaining: 3m 36s\n",
            "443:\tlearn: 0.0113036\ttotal: 2m 52s\tremaining: 3m 35s\n",
            "444:\tlearn: 0.0112819\ttotal: 2m 52s\tremaining: 3m 35s\n",
            "445:\tlearn: 0.0112372\ttotal: 2m 52s\tremaining: 3m 34s\n",
            "446:\tlearn: 0.0112064\ttotal: 2m 53s\tremaining: 3m 34s\n",
            "447:\tlearn: 0.0111735\ttotal: 2m 53s\tremaining: 3m 33s\n"
          ]
        }
      ],
      "source": [
        "master_fn(\"EMG\",\"/content/drive/MyDrive/sample_emg\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}