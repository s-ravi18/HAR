{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-06-11T06:37:11.969672Z","iopub.status.busy":"2022-06-11T06:37:11.969409Z","iopub.status.idle":"2022-06-11T06:37:18.466543Z","shell.execute_reply":"2022-06-11T06:37:18.465807Z","shell.execute_reply.started":"2022-06-11T06:37:11.969642Z"},"trusted":true},"outputs":[],"source":["##Basics\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import regex as re\n","import os\n","import string\n","import time\n","import warnings\n","import json\n","warnings.filterwarnings(\"ignore\")\n","\n","##TSFresh\n","import tsfresh\n","from tsfresh import extract_features\n","from tsfresh.utilities.dataframe_functions import impute\n","\n","##ML scikit learn classes for data preprocessing:\n","from sklearn.preprocessing import StandardScaler,MinMaxScaler,LabelEncoder\n","from sklearn.model_selection import train_test_split\n","\n","##ML scikit learn classes for feature selection:\n","from sklearn.feature_selection import chi2,mutual_info_classif  ### for chi2 and mutual info\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import f_classif  ### for ANOVA\n","from sklearn.feature_selection import RFE  ### for RFE\n","\n","##ML scikit learn classes for model selection:  \n","from xgboost import XGBClassifier\n","from catboost import CatBoostClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","\n","##ML scikit learn classes for evaluating model:\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import classification_report,accuracy_score,make_scorer,confusion_matrix\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import learning_curve\n","\n","##ML scikit learn classes for creating Pipeline:\n","from sklearn.pipeline import Pipeline\n","\n","## Autokeras Library:\n","import autokeras as ak\n","from autokeras import StructuredDataClassifier\n","\n","from tensorflow.keras.models import load_model\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing:\n","\n","### Used Dataset:imu-dataset-original"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Iterate through the list of alphabets\n","## Create a function that takes in letter for file path, i.e \"K\" \n","## Select each file using file path\n","## Store the csv file name with emg as emg variable(type:Dataframe), file name with other names as nemg(type:Dataframe)\n","## Concatenate it with previous variables and return final eng,nemg\n","## Pass it into the same function with different letter"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dir=\"../input/imu-dataset-original/IMU dataset\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def funct_preprocessing(l,f,fn):\n","    \n","    emg=pd.DataFrame(columns=['timestamp', 'emg1', 'emg2', 'emg3', 'emg4', 'emg5', 'emg6', 'emg7',\n","       'emg8'])\n","    acc=pd.DataFrame()\n","    gyro=pd.DataFrame()\n","    \n","    for i in sorted(os.listdir(os.path.join(dir,l))):\n","        \n","        if \"emg\" in i:\n","            emg=pd.concat([emg,pd.read_csv(os.path.join(dir,l,i))],axis=0)\n","            \n","        elif \"acc\" in i or \"gyro\" in i:  \n","        #### accelerometer,gyro,orientation have same feature names. Hence changing the column names\n","            if \"acc\" in i:\n","                temp=pd.read_csv(os.path.join(dir,l,i))\n","                acc=pd.concat([acc,temp])\n","\n","            elif \"gyro\" in i:\n","                temp=pd.read_csv(os.path.join(dir,l,i))\n","                gyro=pd.concat([gyro,temp])\n","\n","    acc.columns=[\"timestamp\",\"x_acc\",\"y_acc\",\"z_acc\"]\n","    acc.drop(\"timestamp\",axis=1,inplace=True)\n","    gyro.columns=[\"timestamp\",\"x_gyro\",\"y_gyro\",\"z_gyro\"]\n","        \n","    nemg=pd.concat([acc,gyro],axis=1)\n","    \n","    emg[\"label\"]=l\n","    nemg[\"label\"]=l\n","    \n","    f=pd.concat([f,emg],axis=0)\n","    fn=pd.concat([fn,nemg],axis=0)\n","    \n","    return f,fn"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["f=pd.DataFrame()\n","fn=pd.DataFrame()\n","for i in list(string.ascii_uppercase):\n","    f,fn=funct_preprocessing(i,f,fn)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["f.to_csv(\"IMU_EMG.csv\",index=False)\n","fn.to_csv(\"IMU_NonEMG_acc_and_gyro_only.csv\",index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# TSFresh with 50% Overlap:\n","\n","### for EMG Dataset: WS=200\n","### for Non-EMG Dataset: WS=55\n","\n","### Used Dataset:imu-dataset-original"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Function to include time and id columns in the data:\n","def id_time(df,step):\n","    \n","    #Removing unwanted columns.\n","    df.drop(columns=[i for i in df.columns if \"timestamp\" in i],inplace=True)\n","        \n","    #Sliding Window with 50% overlap:\n","    w,t=step,(step//2)\n","    r = np.arange(len(df))  # creating an array\n","    s = r[::t]              #selecting elements with a step of t, i.e. half of SL\n","    z = list(zip(s, s + w)) #Creating a list of tuples, each tuple holding the starting and ending row numbers.\n","    g = lambda t: df.iloc[t[0]:t[1]]\n","    j=pd.concat(map(g, z))\n","    \n","    j[\"id\"]=0\n","    j[\"time\"]=0 \n","    \n","    l=np.arange(0,len(j),step=step)\n","    l=np.append(l,len(j))\n","    \n","    j.reset_index(drop=True,inplace=True)\n","    \n","    #Sliding Window:    \n","    for i in range(len(l)-1):\n","        time = np.arange(len(j[l[i]:l[i+1]]))\n","        t_id=np.full(len(time),i)\n","        j.iloc[l[i]:l[i+1],list(j.columns).index(\"time\")]=time\n","        j.iloc[l[i]:l[i+1],list(j.columns).index(\"id\")]=t_id\n","                \n","    return j\n","\n","## Function to extract time series features from the data:\n","def funct_tsfresh(df):\n","    #Extracting Features\n","    df_extracted = extract_features(df, column_id=\"id\", column_sort=\"time\")\n","    \n","    #Imputing the NaNs\n","    df_extracted=impute(df_extracted)\n","    \n","    return df_extracted"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Function to complete the preprocessing (combining files) and feature extraction process\n","def funct_preprocessing(l,f,fn):\n","    \n","    emg=pd.DataFrame(columns=['timestamp', 'emg1', 'emg2', 'emg3', 'emg4', 'emg5', 'emg6', 'emg7',\n","       'emg8'])\n","    acc=pd.DataFrame()\n","    gyro=pd.DataFrame()\n","    euler=pd.DataFrame()\n","    ori=pd.DataFrame()\n","    \n","    for i in sorted(os.listdir(os.path.join(dir,l))):\n","        \n","        if \"emg\" in i:\n","            emg=pd.concat([emg,pd.read_csv(os.path.join(dir,l,i))],axis=0)\n","            \n","        elif \"acc\" in i or \"gyro\" in i or \"orientation\" in i:  \n","        #### accelerometer,gyro,orientation have same feature names. Hence changing the column names\n","            if \"acc\" in i:\n","                temp=pd.read_csv(os.path.join(dir,l,i))\n","                acc=pd.concat([acc,temp])\n","\n","            elif \"gyro\" in i:\n","                temp=pd.read_csv(os.path.join(dir,l,i))\n","                gyro=pd.concat([gyro,temp])\n","                \n","            elif \"Euler\" in i:\n","                temp=pd.read_csv(os.path.join(dir,l,i))\n","                euler=pd.concat([euler,temp])\n","                \n","            else:\n","                temp=pd.read_csv(os.path.join(dir,l,i))\n","                ori=pd.concat([ori,temp])\n","\n","    acc.columns=[\"timestamp\",\"x_acc\",\"y_acc\",\"z_acc\"]\n","    acc.drop(\"timestamp\",axis=1,inplace=True)\n","    gyro.columns=[\"timestamp\",\"x_gyro\",\"y_gyro\",\"z_gyro\"]\n","    gyro.drop(\"timestamp\",axis=1,inplace=True)\n","    ori.columns=[\"timestamp\",\"x_ori\",\"y_ori\",\"z_ori\",\"w\"]\n","    ori.drop(\"timestamp\",axis=1,inplace=True)\n","    \n","    nemg=pd.concat([acc,gyro,ori,euler],axis=1)\n","    \n","    emg.reset_index(drop=True,inplace=True)\n","    nemg.reset_index(drop=True,inplace=True)\n","    \n","    type_emg={\"emg1\":float,\n","          \"emg2\":float,\n","          \"emg3\":float,\n","          \"emg4\":float,\n","          \"emg5\":float,\n","          \"emg6\":float,\n","          \"emg7\":float,\n","          \"emg8\":float\n","    }\n","    emg=emg.astype(type_emg)\n","    \n","###Now comes the TSFresh Part(Unsupervised)\n","\n","    emg=id_time(emg,200)\n","    emg=funct_tsfresh(emg)\n","    nemg=id_time(nemg,55)\n","    nemg=funct_tsfresh(nemg)    \n","    \n","    emg[\"label\"]=l\n","    nemg[\"label\"]=l\n","    \n","    f=pd.concat([f,emg],axis=0)\n","    fn=pd.concat([fn,nemg],axis=0)\n","    \n","    return f,fn"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## To cross-validate the code:\n","#fn.groupby([\"id\"]).agg(\"count\")  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## To save time:\n","start=X   #### X is the custom value, like 18-21\n","end=X+3\n","f=pd.DataFrame()\n","fn=pd.DataFrame()\n","for i in list(string.ascii_uppercase)[start:end]:\n","    f,fn=funct_preprocessing(i,f,fn)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["f.to_csv(f\"IMU_EMG_AfterTSFresh_{start}-{end}.csv\",index=False)\n","fn.to_csv(f\"IMU_NonEMG_AfterTSFresh_{start}-{end}.csv\",index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Feature Selection:"]},{"cell_type":"markdown","metadata":{},"source":["There are various Feature selection methods that can be used:\n","1. ANOVA - FILTER Method of FS\n","2. CHI2 - FILTER Method of FS\n","3. RFE - WRAPPER Method of FS\n","4. Mutual Info - FILTER Method of FS\n","\n","There are other methods of FS like:\n","1. Feature Importance of individual models - EMBEDDED Method of FS\n","2. Pearson's Correlation\n","3. Spearman's Rank Correlation\n","4. PCA - FILTER Method of FS"]},{"cell_type":"markdown","metadata":{},"source":["## For Combining individual zip files:\n","## Used Dataset:after-tsfresh-imu"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-19T09:23:02.155233Z","iopub.status.busy":"2022-05-19T09:23:02.154904Z","iopub.status.idle":"2022-05-19T09:23:02.159538Z","shell.execute_reply":"2022-05-19T09:23:02.158376Z","shell.execute_reply.started":"2022-05-19T09:23:02.155203Z"},"trusted":true},"outputs":[],"source":["## Combining all the files:\n","dir=\"../input/after-tsfresh-imu\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-19T09:23:02.69262Z","iopub.status.busy":"2022-05-19T09:23:02.691939Z","iopub.status.idle":"2022-05-19T09:23:11.57276Z","shell.execute_reply":"2022-05-19T09:23:11.57147Z","shell.execute_reply.started":"2022-05-19T09:23:02.692582Z"},"trusted":true},"outputs":[],"source":["emg=pd.DataFrame()\n","for i in os.listdir(dir):\n","    for j in os.listdir(os.path.join(dir,i)):\n","        if \"_EMG_\" in j:\n","            emg=pd.concat([emg,pd.read_csv(os.path.join(dir,i,j))],axis=0)\n","            \n","nemg=pd.DataFrame()\n","for i in os.listdir(dir):\n","    for j in os.listdir(os.path.join(dir,i)):\n","        if \"_NonEMG_\" in j:\n","            nemg=pd.concat([nemg,pd.read_csv(os.path.join(dir,i,j))],axis=0)\n","            "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["emg.to_csv(\"Combined_EMG.csv\",index=False)\n","nemg.to_csv(\"Combined_NEMG.csv\",index=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Created a dataset called imu-for-feature-selection"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-21T17:18:13.96737Z","iopub.status.busy":"2022-04-21T17:18:13.966869Z","iopub.status.idle":"2022-04-21T17:19:43.348749Z","shell.execute_reply":"2022-04-21T17:19:43.346844Z","shell.execute_reply.started":"2022-04-21T17:18:13.967339Z"},"trusted":true},"outputs":[],"source":["df=pd.read_csv(\"../input/imu-for-feature-selection/Combined_EMG.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-21T17:20:42.889342Z","iopub.status.busy":"2022-04-21T17:20:42.888794Z","iopub.status.idle":"2022-04-21T17:23:02.521158Z","shell.execute_reply":"2022-04-21T17:23:02.519948Z","shell.execute_reply.started":"2022-04-21T17:20:42.889311Z"},"trusted":true},"outputs":[],"source":["imu=pd.read_csv(\"../input/imu-for-feature-selection/Combined_NEMG.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-21T17:23:02.523489Z","iopub.status.busy":"2022-04-21T17:23:02.523198Z","iopub.status.idle":"2022-04-21T17:23:02.530018Z","shell.execute_reply":"2022-04-21T17:23:02.529271Z","shell.execute_reply.started":"2022-04-21T17:23:02.523451Z"},"trusted":true},"outputs":[],"source":["imu.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-21T17:19:43.351955Z","iopub.status.busy":"2022-04-21T17:19:43.351649Z","iopub.status.idle":"2022-04-21T17:19:43.36123Z","shell.execute_reply":"2022-04-21T17:19:43.360046Z","shell.execute_reply.started":"2022-04-21T17:19:43.351918Z"},"trusted":true},"outputs":[],"source":["df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-21T17:19:43.363661Z","iopub.status.busy":"2022-04-21T17:19:43.36335Z","iopub.status.idle":"2022-04-21T17:19:43.423609Z","shell.execute_reply":"2022-04-21T17:19:43.422975Z","shell.execute_reply.started":"2022-04-21T17:19:43.363629Z"},"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-20T06:15:58.099318Z","iopub.status.busy":"2022-04-20T06:15:58.098995Z","iopub.status.idle":"2022-04-20T06:15:58.106947Z","shell.execute_reply":"2022-04-20T06:15:58.105976Z","shell.execute_reply.started":"2022-04-20T06:15:58.099282Z"},"trusted":true},"outputs":[],"source":["def initial(df):\n","    \n","    #### Label Encoding the Target Variable\n","\n","    X=df.drop([\"label\"],axis=1)\n","    y=df[\"label\"]\n","    le=LabelEncoder()\n","    y=le.fit_transform(y)\n","    y= pd.Series(y)\n","\n","    #### Removing Features having zero variance.\n","\n","    Var=X[X.columns].std()\n","    col=Var[Var==0].index\n","    X=X.drop(col,axis=1)\n","    \n","    return X,y"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-20T16:15:38.464917Z","iopub.status.busy":"2022-04-20T16:15:38.464547Z","iopub.status.idle":"2022-04-20T16:15:38.500216Z","shell.execute_reply":"2022-04-20T16:15:38.499575Z","shell.execute_reply.started":"2022-04-20T16:15:38.46482Z"},"trusted":true},"outputs":[],"source":["def draw_curve(train_sizes, train_scores, test_scores):\n","    train_scores_mean = np.mean(train_scores, axis=1)\n","    train_scores_std = np.std(train_scores, axis=1)\n","    test_scores_mean = np.mean(test_scores, axis=1)\n","    test_scores_std = np.std(test_scores, axis=1)\n","    \n","    plt.figure(figsize=(10,10))\n","    plt.xlabel(\"Training examples\")\n","    plt.ylabel(\"Score\")\n","    plt.gca().invert_yaxis()\n","    \n","    # box-like grid\n","    plt.grid()\n","    \n","    # plot the std deviation as a transparent range at each training set size\n","    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n","    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n","    \n","    # plot the average training and test score lines at each training set size\n","    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n","    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n","    \n","    # sizes the window for readability and displays the plot\n","    # shows error from 0 to 1.1\n","    plt.legend(loc=\"best\")\n","    plt.ylim(-.1,1.1)\n","    plt.show()\n","       \n","\n","def classification_report_with_accuracy_score(y_true, y_pred):\n","\n","    print(classification_report(y_true, y_pred)) # print classification report\n","    cm=confusion_matrix(y_true,y_pred)\n","    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # For normalising the Matrix for better visualisation.\n","    plt.figure(figsize=(20,10))\n","    plt.rc(\"font\",size=10)\n","    sns.heatmap(cm,annot=True,fmt=\".2f\",cmap=\"viridis\")\n","    plt.show()\n","    return accuracy_score(y_true, y_pred) # return accuracy score\n","\n","def fun_best(X,y):\n","    \n","    X.rename({\"emg6__value_count__value_-1\":\"emg6__value_count__value_2\"},axis=1,inplace=True)\n","\n","    #To remove JSON characters from column names because LGBM fails to execute    \n","    X = X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n","    \n","    models={\"XGB\":XGBClassifier(),\"LGBM\":LGBMClassifier(),\"GradientBoost\":GradientBoostingClassifier(),\"LDA\":LinearDiscriminantAnalysis(),\"RandomForest\":RandomForestClassifier()}\n","    mean_score=[]\n","    \n","    for i,j in models.items():\n","        try:\n","            \n","            model=j\n","            score_model=cross_val_score(model,X,y,cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),scoring=make_scorer(classification_report_with_accuracy_score))\n","            mean_score.append(score_model.mean())\n","            train_sizes, train_scores, test_scores = learning_curve(model, X, y, n_jobs=-1, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n","            draw_curve(train_sizes, train_scores, test_scores)\n","        \n","        except:\n","            \n","            model=j\n","            score_model=cross_val_score(model,X,y,cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),scoring=make_scorer(classification_report_with_accuracy_score))\n","            mean_score.append(score_model.mean())\n","            train_sizes, train_scores, test_scores = learning_curve(model, X, y, n_jobs=-1, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n","            draw_curve(train_sizes, train_scores, test_scores)            \n","        \n","    result=dict(zip(models.keys(),mean_score))\n","   \n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-20T06:16:07.885335Z","iopub.status.busy":"2022-04-20T06:16:07.884632Z","iopub.status.idle":"2022-04-20T06:16:07.89501Z","shell.execute_reply":"2022-04-20T06:16:07.894396Z","shell.execute_reply.started":"2022-04-20T06:16:07.885286Z"},"trusted":true},"outputs":[],"source":["def funct_FS_bestmodel(ds,fs_name,n):\n","    \n","    df=pd.read_csv(f\"../input/imu-for-feature-selection/Combined_{ds}.csv\")\n","    \n","    print(\"Read the Dataset\")\n","    \n","    X,y=initial(df)\n","\n","    print(\"Passed initial function\")\n","    \n","    fs_dic={\"MI\":SelectKBest(mutual_info_classif, k=n),\"CHI2\":SelectKBest(chi2, k=n),\"ANOVA\":SelectKBest(f_classif, k=n),\"RFE\":RFE(estimator=CatBoostClassifier(), n_features_to_select=n)}\n","    \n","    ### for Chi2 feature selection, data points must be strictly positive.\n","    \n","    if fs_name==\"CHI2\":\n","        pipe = Pipeline([('scaler', MinMaxScaler()),\n","                 ('selector', fs_dic[fs_name])])\n","    \n","    else:\n","        pipe = Pipeline([('scaler', StandardScaler()),\n","                 ('selector', fs_dic[fs_name])])\n","    \n","    print(\"Pipeline set up\")\n","    \n","    pipe.fit(X, y)\n","    # Get columns to keep and create new dataframe with those only\n","    cols = pipe.named_steps['selector'].get_support(indices=True) ### Note the format\n","    X_fs= X.iloc[:,cols]\n","\n","    df_fs=pd.concat([X_fs,y],axis=1)\n","    df_fs.rename({\"0\":\"label\"},axis=1,inplace=True)\n","    df_fs.to_csv(f\"{ds}_{fs_name}_{n}_features.csv\",index=False)\n","    \n","    print(\"Done Feature Selection\")\n","    \n","    result=fun_best(X_fs,y)\n","    print(f\"Top {n} features using {fs_name} technique:\")\n","    print(result)    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## To check the Corresponding Letter -> Number Encoding\n","target=pd.DataFrame(np.hstack([y.values.reshape((-1,1)),y_label.reshape((-1,1))]),columns=[\"label\",\"label_encoded\"])\n","target.drop_duplicates().sort_values(\"label\").reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-20T06:16:12.074486Z","iopub.status.busy":"2022-04-20T06:16:12.074172Z"},"trusted":true},"outputs":[],"source":["### For Trial:\n","### Params are (\"EMG\" or \"NEMG\"/ Selection Method Name / Number of features)\n","funct_FS_bestmodel(\"EMG\",\"CHI2\",200) "]},{"cell_type":"markdown","metadata":{},"source":["# Stacked Ensemble Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-19T09:23:24.420897Z","iopub.status.busy":"2022-05-19T09:23:24.420575Z","iopub.status.idle":"2022-05-19T09:24:38.307486Z","shell.execute_reply":"2022-05-19T09:24:38.306457Z","shell.execute_reply.started":"2022-05-19T09:23:24.420866Z"},"trusted":true},"outputs":[],"source":["!pip install autokeras\n","import autokeras\n","from autokeras import StructuredDataClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-19T09:24:38.309857Z","iopub.status.busy":"2022-05-19T09:24:38.309625Z","iopub.status.idle":"2022-05-19T09:24:38.313629Z","shell.execute_reply":"2022-05-19T09:24:38.312823Z","shell.execute_reply.started":"2022-05-19T09:24:38.30983Z"},"trusted":true},"outputs":[],"source":["### Dictionary for getting Accuracies:\n","accuracy={}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-19T09:24:38.315825Z","iopub.status.busy":"2022-05-19T09:24:38.314984Z","iopub.status.idle":"2022-05-19T09:24:38.335185Z","shell.execute_reply":"2022-05-19T09:24:38.334213Z","shell.execute_reply.started":"2022-05-19T09:24:38.315777Z"},"trusted":true},"outputs":[],"source":["### Copied from above section:\n","def initial(df):\n","    \n","    #### Label Encoding the Target Variable\n","\n","    X=df.drop([\"label\"],axis=1)\n","    y=df[\"label\"]\n","    if df.label.dtype==str:   ### Will apply label encoding if needed\n","        le=LabelEncoder()\n","        y=le.fit_transform(y)\n","        y=pd.Series(y)\n","\n","    #### Removing Features having zero variance.\n","\n","    Var=X[X.columns].std()\n","    col=Var[Var==0].index\n","    X=X.drop(col,axis=1)\n","    \n","    return X,y"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-19T09:24:38.337899Z","iopub.status.busy":"2022-05-19T09:24:38.337565Z","iopub.status.idle":"2022-05-19T09:24:38.349942Z","shell.execute_reply":"2022-05-19T09:24:38.349321Z","shell.execute_reply.started":"2022-05-19T09:24:38.337858Z"},"trusted":true},"outputs":[],"source":["def funct_FS(ds,fs_name,n,X,y):\n","    \n","    fs_dic={\"MI\":SelectKBest(mutual_info_classif, k=n),\"CHI2\":SelectKBest(chi2, k=n),\"ANOVA\":SelectKBest(f_classif, k=n),\"RFE\":RFE(estimator=CatBoostClassifier(), n_features_to_select=n)}    \n","    ### for Chi2 feature selection, data points must be strictly positive.    \n","    if fs_name==\"CHI2\":\n","        pipe = Pipeline([('scaler', MinMaxScaler()),\n","                 ('selector', fs_dic[fs_name])])\n","    \n","    else:\n","        pipe = Pipeline([('scaler', StandardScaler()),\n","                 ('selector', fs_dic[fs_name])])    \n","    print(\"Pipeline set up\")\n","    \n","    pipe.fit(X, y)\n","    # Get columns to keep and create new dataframe with those only\n","    cols = pipe.named_steps['selector'].get_support(indices=True) ### Note the format\n","    X_fs= X.iloc[:,cols]\n","\n","    df_fs=pd.concat([X_fs,y],axis=1)\n","    df_fs.rename({\"0\":\"label\"},axis=1,inplace=True)\n","    df_fs.to_csv(f\"{ds}_{fs_name}_{n}_features.csv\",index=False)    \n","    return df_fs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-19T09:24:38.352176Z","iopub.status.busy":"2022-05-19T09:24:38.351892Z","iopub.status.idle":"2022-05-19T09:24:38.3632Z","shell.execute_reply":"2022-05-19T09:24:38.361997Z","shell.execute_reply.started":"2022-05-19T09:24:38.352147Z"},"trusted":true},"outputs":[],"source":["def funct_autokeras_accuracy(X_train, X_test, y_train, y_test,max_trials,data,feature_count):\n","    \n","    search = StructuredDataClassifier(max_trials=max_trials)\n","    \n","    # perform the search\n","    search.fit(x=X_train, y=y_train, verbose=0)\n","    \n","    # evaluate the model\n","    loss, acc = search.evaluate(X_test, y_test, verbose=0)\n","    accuracy[f\"{data}_{feature_count}_{max_trials}\"]=round(acc, 3)     \n","    \n","    # get the best performing model\n","    model = search.export_model()   \n","    \n","    # save the best performing model to file (Autokeras Model fails to save as h5 file)\n","    try:\n","        model.save(f\"{data}_{feature_count}_{max_trials}\", save_format=\"tf\")\n","    except Exception:\n","        model.save(f\"{data}_{feature_count}_{max_trials}.h5\")"]},{"cell_type":"markdown","metadata":{},"source":["Function to find out best model using autokeras library.\n","\n","Parameters description: feature_count - no of features to be selected\n","\n","                    max_trials - for the autokeras\n","                        \n","                    data -  EMG/NEMG                     "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-19T09:28:57.271597Z","iopub.status.busy":"2022-05-19T09:28:57.270693Z","iopub.status.idle":"2022-05-19T09:28:57.280852Z","shell.execute_reply":"2022-05-19T09:28:57.279781Z","shell.execute_reply.started":"2022-05-19T09:28:57.271548Z"},"trusted":true},"outputs":[],"source":["def funct_autokeras(feature_count,max_trials,data,X,y):    ### data=\"EMG\"/\"NEMG\"/\"Both\" ### feature_count=NULL in case of \"Both\"\n","    if feature_count!=\"None\":\n","        df_fs=funct_FS(data,\"ANOVA\",feature_count,X,y)  ### fs_name=\"ANOVA\"  ### (ds,fs_name,n,X,y)\n","        df_fs.rename({0:\"label\"},axis=1,inplace=True)        \n","        X=df_fs.drop([\"label\"],axis=1)\n","        y=df_fs[\"label\"]\n","    else:\n","        X=X\n","        y=y\n","\n","    ### Splitting the data:\n","    X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y,test_size=0.3, random_state=1)\n","    \n","    ### Scaling the Data:\n","    sc=StandardScaler()\n","    X_train_scaled=sc.fit_transform(X_train)\n","    X_test_scaled=sc.transform(X_test)    \n","    \n","    funct_autokeras_accuracy(X_train_scaled, X_test_scaled, y_train, y_test,max_trials,data,feature_count)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-19T09:27:00.693585Z","iopub.status.busy":"2022-05-19T09:27:00.693291Z","iopub.status.idle":"2022-05-19T09:27:09.701937Z","shell.execute_reply":"2022-05-19T09:27:09.701033Z","shell.execute_reply.started":"2022-05-19T09:27:00.693556Z"},"trusted":true},"outputs":[],"source":["#Debugging\n","#df_fs=funct_FS(\"EMG\",\"ANOVA\",100,X,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-19T09:24:38.382785Z","iopub.status.busy":"2022-05-19T09:24:38.381929Z","iopub.status.idle":"2022-05-19T09:25:57.32015Z","shell.execute_reply":"2022-05-19T09:25:57.318792Z","shell.execute_reply.started":"2022-05-19T09:24:38.382751Z"},"trusted":true},"outputs":[],"source":["df_ori=pd.read_csv(\"../input/imu-for-feature-selection/Combined_EMG.csv\")  ### NEMG/EMG"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-19T09:25:57.322602Z","iopub.status.busy":"2022-05-19T09:25:57.322322Z","iopub.status.idle":"2022-05-19T09:26:05.017975Z","shell.execute_reply":"2022-05-19T09:26:05.016883Z","shell.execute_reply.started":"2022-05-19T09:25:57.322566Z"},"trusted":true},"outputs":[],"source":["X,y=initial(df_ori)   ### Remains Fixed"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-19T09:29:01.115127Z","iopub.status.busy":"2022-05-19T09:29:01.11483Z","iopub.status.idle":"2022-05-19T09:29:37.068429Z","shell.execute_reply":"2022-05-19T09:29:37.067016Z","shell.execute_reply.started":"2022-05-19T09:29:01.115097Z"},"trusted":true},"outputs":[],"source":["### Iterating through various values:\n","for feature_count in list(range(100,301,100)): ### No of features to be selected\n","    for max_trials in list(range(16,21)):  ### Trial count for autokeras\n","        funct_autokeras(feature_count,max_trials,\"EMG\",X,y)    \n","    print(f\"Done for {feature_count}!\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#### To store the results in the form of json that is prettified:\n","with open('accuracy_results.json', 'w') as fp:\n","    json.dump(accuracy, fp,  indent=4)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-06-11T06:39:38.249559Z","iopub.status.busy":"2022-06-11T06:39:38.249295Z","iopub.status.idle":"2022-06-11T06:39:40.240188Z","shell.execute_reply":"2022-06-11T06:39:40.239450Z","shell.execute_reply.started":"2022-06-11T06:39:38.249530Z"},"trusted":true},"outputs":[],"source":["### For the best model using EMG and NEMG Features\n","df_emg=pd.read_csv(\"../input/imu-top-200-features/EMG_ANOVA_200_features.csv\")\n","df_nemg=pd.read_csv(\"../input/imu-top-200-features/NEMG_ANOVA_200_features.csv\")\n","df_emg.rename({\"0\":\"label\"},axis=1,inplace=True)\n","df_nemg.rename({\"0\":\"label\"},axis=1,inplace=True)\n","\n","## Combining EMG and IMU files:\n","temp=pd.DataFrame()\n","for i in range(26):\n","    n=df_nemg[df_nemg[\"label\"]==i].reset_index(drop=True)\n","    e=df_emg[df_emg[\"label\"]==i].reset_index(drop=True).drop([\"label\"],axis=1)[0:n.shape[0]]\n","    k=pd.concat([e,n],axis=1)\n","    temp=pd.concat([temp,k],axis=0)   "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Trial 1:\n","accuracy={}\n","X,y=initial(temp)   ### Remains Fixed\n","### Iterating through various values:\n","for max_trials in list(range(16,25)):  ### Trial count for autokeras\n","    funct_autokeras(\"None\",max_trials,\"Both\",X,y)  \n","    print(f\"Done for {max_trials}!\")\n","    \n","#### To store the results in the form of json that is prettified:\n","with open('accuracy_results.json', 'w') as fp:\n","    json.dump(accuracy, fp,  indent=4)\n","\n","### End Result:\n","# {\n","#     \"Both_Null_16\": 0.953,\n","#     \"Both_Null_17\": 0.943,\n","#     \"Both_Null_18\": 0.949,\n","#     \"Both_Null_19\": 0.953,\n","#     \"Both_Null_20\": 0.955,\n","#     \"Both_Null_21\": 0.949,\n","#     \"Both_Null_22\": 0.954,\n","#     \"Both_Null_23\": 0.951,\n","#     \"Both_Null_24\": 0.955\n","# }"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Trial 2:\n","accuracy={}\n","X,y=initial(temp)   ### Remains Fixed\n","### Iterating through various values:\n","for max_trials in list(range(20,41,5)):  ### Trial count for autokeras\n","    funct_autokeras(\"Null\",max_trials,\"Both\",X,y)  \n","    print(f\"Done for {max_trials}!\")\n","    \n","#### To store the results in the form of json that is prettified:\n","with open('400 Features Combined 5-40.json', 'w') as fp:\n","    json.dump(accuracy, fp,  indent=4)\n","\n","### End Result:\n","# {\n","#     \"Both_Null_20\": 0.075,\n","#     \"Both_Null_25\": 0.913,\n","#     \"Both_Null_30\": 0.932,\n","#     \"Both_Null_35\": 0.948,\n","#     \"Both_Null_40\": 0.276\n","# }"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## IMU Best Model Try:\n","accuracy={}\n","X,y=initial(df_nemg)   ### Remains Fixed\n","### Iterating through various values:\n","for max_trials in range(10,30):  ### Trial count for autokeras\n","    funct_autokeras(\"Null\",max_trials,\"IMU\",X,y)  \n","    print(f\"Done for {max_trials}!\")\n","    \n","#### To store the results in the form of json that is prettified:\n","with open('accuracy_results_IMU.json', 'w') as fp:\n","    json.dump(accuracy, fp,  indent=4)\n","\n","### End Result:\n","# {\n","#     \"IMU_Null_10\": 0.695,\n","#     \"IMU_Null_11\": 0.68,\n","#     \"IMU_Null_12\": 0.684,\n","#     \"IMU_Null_13\": 0.702,\n","#     \"IMU_Null_14\": 0.718,\n","#     \"IMU_Null_15\": 0.706,\n","#     \"IMU_Null_16\": 0.75,\n","#     \"IMU_Null_17\": 0.702,\n","#     \"IMU_Null_18\": 0.712,\n","#     \"IMU_Null_19\": 0.72,\n","#     \"IMU_Null_20\": 0.716,\n","#     \"IMU_Null_21\": 0.721,\n","#     \"IMU_Null_22\": 0.7,\n","#     \"IMU_Null_23\": 0.712,\n","#     \"IMU_Null_24\": 0.709,\n","#     \"IMU_Null_25\": 0.707,\n","#     \"IMU_Null_26\": 0.732,\n","#     \"IMU_Null_27\": 0.692,\n","#     \"IMU_Null_28\": 0.711,\n","#     \"IMU_Null_29\": 0.703\n","# }"]},{"cell_type":"markdown","metadata":{},"source":["# Loading the Best Base Learner provided by Autokeras:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Loading the Best Saved Model - max_iterations=24\n","base_model = load_model(\"Trial 1/Base Model\", custom_objects=ak.CUSTOM_OBJECTS)\n","\n","## To get the Best Model summary(Details about its architecture):\n","base_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Model: \"model\"\n","# _________________________________________________________________\n","#  Layer (type)                Output Shape              Param #   \n","# =================================================================\n","#  input_1 (InputLayer)        [(None, 400)]             0         \n","                                                                 \n","#  multi_category_encoding (Mu  (None, 400)              0         \n","#  ltiCategoryEncoding)                                            \n","                                                                 \n","#  normalization (Normalizatio  (None, 400)              801       \n","#  n)                                                              \n","                                                                 \n","#  dense (Dense)               (None, 32)                12832     \n","                                                                 \n","#  re_lu (ReLU)                (None, 32)                0         \n","                                                                 \n","#  dense_1 (Dense)             (None, 128)               4224      \n","                                                                 \n","#  re_lu_1 (ReLU)              (None, 128)               0         \n","                                                                 \n","#  dense_2 (Dense)             (None, 26)                3354      \n","                                                                 \n","#  classification_head_1 (Soft  (None, 26)               0         \n","#  max)                                                            \n","                                                                 \n","# =================================================================\n","# Total params: 21,211\n","# Trainable params: 20,410\n","# Non-trainable params: 801\n","# _________________________________________________________________"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### Copied from above section:\n","def initial(df):\n","    \n","    #### Label Encoding the Target Variable\n","\n","    X=df.drop([\"label\"],axis=1)\n","    y=df[\"label\"]\n","    if df.label.dtype==str:   ### Will apply label encoding if needed\n","        le=LabelEncoder()\n","        y=le.fit_transform(y)\n","        y=pd.Series(y)\n","\n","    #### Removing Features having zero variance.\n","\n","    Var=X[X.columns].std()\n","    col=Var[Var==0].index\n","    X=X.drop(col,axis=1)\n","    \n","    X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y,test_size=0.3, random_state=1)\n","    \n","    ### Scaling the Data:\n","    sc=StandardScaler()\n","    X_train_scaled=sc.fit_transform(X_train)\n","    X_test_scaled=sc.transform(X_test)  \n","    \n","    return X_train_scaled, X_test_scaled, y_train, y_test   ## Changed the return values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### For the best model using EMG and NEMG Features\n","df_emg=pd.read_csv(\"EMG_ANOVA_200_features.csv\")\n","df_nemg=pd.read_csv(\"NEMG_ANOVA_200_features.csv\")\n","df_emg.rename({\"0\":\"label\"},axis=1,inplace=True)\n","df_nemg.rename({\"0\":\"label\"},axis=1,inplace=True)\n","\n","temp=pd.DataFrame()\n","for i in range(26):\n","    n=df_nemg[df_nemg[\"label\"]==i].reset_index(drop=True)\n","    e=df_emg[df_emg[\"label\"]==i].reset_index(drop=True).drop([\"label\"],axis=1)[0:n.shape[0]]\n","    k=pd.concat([e,n],axis=1)\n","    temp=pd.concat([temp,k],axis=0)   \n","\n","X_train_scaled, X_test_scaled, y_train, y_test=initial(temp)   ### Remains Fixed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### Building the model above from scratch in TensorFlow:\n","class Model:\n","    def __init__(self,number,l1,l2):\n","        self.l1=l1\n","        self.l2=l2\n","        self.number=number\n","        self.model = tf.keras.Sequential()\n","        self.model.add(tf.keras.layers.InputLayer(input_shape=(400)))\n","        #model.add(tf.keras.layers.Normalization(axis=-1))\n","        self.model.add(tf.keras.layers.Dense(units=self.l1,activation=\"relu\"))\n","        self.model.add(tf.keras.layers.Dense(units=self.l2,activation=\"relu\"))\n","        self.model.add(tf.keras.layers.Dense(units=26,activation=\"softmax\"))\n","        self.model.compile(optimizer=\"adam\",loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=\"accuracy\")\n","    \n","    def funct_fit(self):\n","        self.model.fit(X_train_scaled,y_train,epochs=50,batch_size=50)\n","        self.model.save(f\"{os.getcwd()}/Trial 1/model_{self.number}.h5\")\n","#         try:\n","#             self.model.save(f\"{os.getcwd()}/Trial 1/model_{self.number}\", save_format=\"tf\")\n","#         except Exception:          "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["### Constructing the other three base models:\n","### Original Model had (l1,l2)=(32,128)\n","model=Model(1,64,256)\n","model.funct_fit()\n","\n","model=Model(2,96,384)\n","model.funct_fit()\n","\n","model=Model(3,128,512)\n","model.funct_fit()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["allmodels=[base_model]\n","\n","#### Loading other models:\n","def funct_load(number):\n","    for i in range(1,number+1):\n","        # load model from file\n","        model = load_model(f'Trial 1/model_{i}.h5')\n","        # add to list of members\n","        allmodels.append(model)\n","            \n","funct_load(3)    \n","allmodels"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# [<keras.engine.functional.Functional at 0x7fcf70f15eb8>,\n","#  <keras.engine.sequential.Sequential at 0x7fcf5a26e550>,\n","#  <keras.engine.sequential.Sequential at 0x7fcf58844b38>,\n","#  <keras.engine.sequential.Sequential at 0x7fcf587b8b70>]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create stacked model input dataset as outputs from the ensemble\n","def stacked_dataset(members, X_test_scaled):\n","    stackX = None\n","    for model in allmodels:\n","        # make prediction\n","        yhat = model.predict(X_test_scaled, verbose=0)\n","        # stack predictions into [rows, members, class]\n","        if stackX is None:\n","            stackX = yhat\n","        else:\n","            stackX = np.dstack((stackX, yhat))\n","    # flatten predictions to [rows, members x class]\n","    stackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n","    return stackX"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# fit a model based on the outputs from the ensemble members\n","def fit_stacked_model(members, X_test_scaled, y_test,model_name):\n","    # create dataset using ensemble\n","    stackedX = stacked_dataset(members, X_test_scaled)\n","    # fit standalone model\n","    model = model_name\n","    model.fit(stackedX, y_test)\n","    return model\n"," \n","# make a prediction with the stacked model\n","def stacked_prediction(members, model, X_test_scaled):\n","    # create dataset using ensemble\n","    stackedX = stacked_dataset(members, X_test_scaled)\n","    # make a prediction\n","    yhat = model.predict(stackedX)\n","    return yhat"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## METALEARNER USED IS LOGISTIC REGRESSION\n","# fit stacked model using the ensemble\n","model = fit_stacked_model(allmodels, X_test_scaled, y_test,LogisticRegression())\n","# evaluate model on test set\n","yhat = stacked_prediction(allmodels, model, X_test_scaled)\n","acc = accuracy_score(y_test, yhat)\n","print('Stacked Test Accuracy: %.3f' % acc)\n","\n","# Stacked Test Accuracy: 0.995"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## METALEARNER USED IS XGBOOST CLASSIFIER\n","# fit stacked model using the ensemble\n","model = fit_stacked_model(allmodels, X_test_scaled, y_test,XGBClassifier())\n","# evaluate model on test set\n","yhat = stacked_prediction(allmodels, model, X_test_scaled)\n","acc = accuracy_score(y_test, yhat)\n","print('Stacked Test Accuracy: %.3f' % acc)\n","\n","# Stacked Test Accuracy: 1.000"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
