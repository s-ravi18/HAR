{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preprocessing of Second DS:","metadata":{}},{"cell_type":"code","source":"l=sorted(os.listdir(\"../input/newds/dataset_single_channel/D1/D1_CH1\"))\n#Class names: cy,hook,lat,palm,spher,tip\n\nlabel=[\"cy\",\"hook\",\"lat\",\"palm\",\"spher\",\"tip\"]\nlabel\n\nd={}\n\nfor i in label:\n    d[i]=[j for j in l if i in j]\npath=\"../input/newds/dataset_single_channel/D1/D1_CH1\"\n\nfor i,j in d.items():\n    df=pd.DataFrame()\n    for k in j:\n        if df.shape[0]==0:\n            df1=pd.DataFrame(pd.read_csv(os.path.join(path,k),header=None).values.reshape(-1,1))\n            df=df1\n        else:\n            df1=pd.DataFrame(pd.read_csv(os.path.join(path,k),header=None).values.reshape(-1,1))\n            df=pd.concat([df,df1],axis=0)\n        \n    df.to_csv(f\"D1_CH1_{i}.csv\",index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Combining Files:","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nlabel=[\"cy\",\"hook\",\"lat\",\"palm\",\"spher\",\"tip\"]\nDIR=\"../input/after-tsfresh/After TSFresh/D1/C1\"\n\ndf_mega=pd.DataFrame()\ndf_label=pd.DataFrame()\n\nl=sorted(os.listdir(DIR))\n\nfor i in range(6):\n    if len(df_mega)==0:\n        df=pd.read_csv(os.path.join(DIR,l[i]))\n        df_mega=df\n        \n        df_label[\"Label\"]=np.array([label[i] for u in range(len(df_mega))])\n        \n    else:\n        x=pd.read_csv(os.path.join(DIR,l[i]))\n        arr=pd.DataFrame()\n        arr[\"Label\"]=np.array([label[i] for u in range(len(x))])\n        \n        df_mega=pd.concat([df_mega,x])\n        df_label=pd.concat([df_label,arr])\n\ndf_combined=pd.concat([df_mega,df_label],axis=1)\ndf_combined=df_combined.reset_index(drop=True)\ndf_combined.to_csv(\"Combined D1_C1.csv\",index=False)   \n\nDIR=\"../input/after-tsfresh/After TSFresh/D1/C2\"\n\ndf_mega=pd.DataFrame()\ndf_label=pd.DataFrame()\n\nl=sorted(os.listdir(DIR))\n\nfor i in range(6):\n    if len(df_mega)==0:\n        df=pd.read_csv(os.path.join(DIR,l[i]))\n        df_mega=df\n        \n        df_label[\"Label\"]=np.array([label[i] for u in range(len(df_mega))])\n        \n    else:\n        x=pd.read_csv(os.path.join(DIR,l[i]))\n        arr=pd.DataFrame()\n        arr[\"Label\"]=np.array([label[i] for u in range(len(x))])\n        \n        df_mega=pd.concat([df_mega,x])\n        df_label=pd.concat([df_label,arr])\n\ndf_combined=pd.concat([df_mega,df_label],axis=1)\ndf_combined=df_combined.reset_index(drop=True)\ndf_combined.to_csv(\"Combined D1_C2.csv\",index=False)   \n\nDIR=\"../input/after-tsfresh/After TSFresh/D2/C1\"\n\ndf_mega=pd.DataFrame()\ndf_label=pd.DataFrame()\n\nl=sorted(os.listdir(DIR))\n\nfor i in range(6):\n    if len(df_mega)==0:\n        df=pd.read_csv(os.path.join(DIR,l[i]))\n        df_mega=df\n        \n        df_label[\"Label\"]=np.array([label[i] for u in range(len(df_mega))])\n        \n    else:\n        x=pd.read_csv(os.path.join(DIR,l[i]))\n        arr=pd.DataFrame()\n        arr[\"Label\"]=np.array([label[i] for u in range(len(x))])\n        \n        df_mega=pd.concat([df_mega,x])\n        df_label=pd.concat([df_label,arr])\n\ndf_combined=pd.concat([df_mega,df_label],axis=1)\ndf_combined=df_combined.reset_index(drop=True)\ndf_combined.to_csv(\"Combined D2_C1.csv\",index=False)   \n\nDIR=\"../input/after-tsfresh/After TSFresh/D2/C2\"\n\ndf_mega=pd.DataFrame()\ndf_label=pd.DataFrame()\n\nl=sorted(os.listdir(DIR))\n\nfor i in range(6):\n    if len(df_mega)==0:\n        df=pd.read_csv(os.path.join(DIR,l[i]))\n        df_mega=df\n        \n        df_label[\"Label\"]=np.array([label[i] for u in range(len(df_mega))])\n        \n    else:\n        x=pd.read_csv(os.path.join(DIR,l[i]))\n        arr=pd.DataFrame()\n        arr[\"Label\"]=np.array([label[i] for u in range(len(x))])\n        \n        df_mega=pd.concat([df_mega,x])\n        df_label=pd.concat([df_label,arr])\n\ndf_combined=pd.concat([df_mega,df_label],axis=1)\ndf_combined=df_combined.reset_index(drop=True)\ndf_combined.to_csv(\"Combined D2_C2.csv\",index=False)   ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TSFresh ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport tsfresh\nfrom tsfresh import extract_features\nfrom tsfresh.utilities.dataframe_functions import impute\n\ndef funct_preprocessing(df):\n    l=np.arange(0,df.shape[0]+1,step=500)\n\n    #Sliding Window:    \n    for i in range(len(l)-1):   \n        k=1\n        for j in range(l[i],l[i+1]):\n            df.loc[j,\"time\"]=k\n            df.loc[j,\"id\"]=i\n            k=k+1\n\n    return df\n\ndef funct_tsfresh(df):\n    #Extracting Features\n    df_extracted = extract_features(df, column_id=\"id\", column_sort=\"time\")\n    \n    #Imputing the NaNs\n    df_extracted=impute(df_extracted)\n    \n    return df_extracted\n\npath=\"../input/for-tsfresh/DS for TSFRESH/D1/C1\"\nl=os.listdir(path)\n\n\nfor i in l[0:3]:\n    df=pd.read_csv(os.path.join(path,i))\n    df.head()\n    print(\"--------\")\n    df=funct_preprocessing(df)\n    df.head()\n    #print(\"--------\")\n    df_e=funct_tsfresh(df)\n    df_e.to_csv(f\"{i}.csv\",index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL SELECTION:","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nlabel=[\"cy\",\"hook\",\"lat\",\"palm\",\"spher\",\"tip\"]\n\ndf_combined1=pd.read_csv(\"../input/for-feature-selection/Combined Files with label/Combined D1_C2.csv\")   \ndf_combined2=pd.read_csv(\"../input/for-feature-selection/Combined Files with label/Combined D2_C2.csv\")   ","metadata":{"execution":{"iopub.execute_input":"2021-10-15T19:28:46.000031Z","iopub.status.busy":"2021-10-15T19:28:45.998885Z","iopub.status.idle":"2021-10-15T19:28:47.100779Z","shell.execute_reply":"2021-10-15T19:28:47.101385Z","shell.execute_reply.started":"2021-10-15T19:24:33.887063Z"},"papermill":{"duration":1.119697,"end_time":"2021-10-15T19:28:47.101689","exception":false,"start_time":"2021-10-15T19:28:45.981992","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_combined=pd.concat([df_combined1,df_combined2],axis=0)","metadata":{"execution":{"iopub.execute_input":"2021-10-15T19:28:47.129297Z","iopub.status.busy":"2021-10-15T19:28:47.128663Z","iopub.status.idle":"2021-10-15T19:28:47.145204Z","shell.execute_reply":"2021-10-15T19:28:47.144622Z","shell.execute_reply.started":"2021-10-15T19:24:34.898545Z"},"papermill":{"duration":0.030939,"end_time":"2021-10-15T19:28:47.145376","exception":false,"start_time":"2021-10-15T19:28:47.114437","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_combined.shape","metadata":{"execution":{"iopub.execute_input":"2021-10-15T19:28:47.176341Z","iopub.status.busy":"2021-10-15T19:28:47.172382Z","iopub.status.idle":"2021-10-15T19:28:47.180039Z","shell.execute_reply":"2021-10-15T19:28:47.179538Z","shell.execute_reply.started":"2021-10-15T19:24:34.916775Z"},"papermill":{"duration":0.022577,"end_time":"2021-10-15T19:28:47.180185","exception":false,"start_time":"2021-10-15T19:28:47.157608","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import chi2,mutual_info_classif\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.preprocessing import StandardScaler\n\nlabel=[\"cy\",\"hook\",\"lat\",\"palm\",\"spher\",\"tip\"]\n\ndf=df_combined.copy()\n\nX=df.drop([\"Label\"],axis=1)\ny=df[\"Label\"]\ny=y.apply(lambda x:label.index(x))\n\nVar=X[X.columns].std()\ncol=Var[Var==0].index\nX=X.drop(col,axis=1)\nX.shape","metadata":{"execution":{"iopub.execute_input":"2021-10-15T19:28:47.21512Z","iopub.status.busy":"2021-10-15T19:28:47.214433Z","iopub.status.idle":"2021-10-15T19:28:48.493064Z","shell.execute_reply":"2021-10-15T19:28:48.492512Z","shell.execute_reply.started":"2021-10-15T19:24:34.934392Z"},"papermill":{"duration":1.298541,"end_time":"2021-10-15T19:28:48.49323","exception":false,"start_time":"2021-10-15T19:28:47.194689","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ANOVA:","metadata":{}},{"cell_type":"code","source":"s=\"54\"\nl=list(map(int,s.split()))\ncols=[list(X.columns)[i] for i in l]\nX=X.drop(cols,axis=1)","metadata":{"execution":{"iopub.execute_input":"2021-10-15T19:28:48.521643Z","iopub.status.busy":"2021-10-15T19:28:48.520986Z","iopub.status.idle":"2021-10-15T19:28:48.534361Z","shell.execute_reply":"2021-10-15T19:28:48.533781Z","shell.execute_reply.started":"2021-10-15T05:11:21.399557Z"},"papermill":{"duration":0.028785,"end_time":"2021-10-15T19:28:48.534528","exception":false,"start_time":"2021-10-15T19:28:48.505743","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create and fit selector\nselector = SelectKBest(f_classif, k=50)\nselector.fit(X, y)\n# Get columns to keep and create new dataframe with those only\ncols = selector.get_support(indices=True)\nX_fs= X.iloc[:,cols]\n\ndf_fs=pd.concat([X_fs,y],axis=1)\n\ndf_fs.to_csv(\"ANOVA_D2_C2.csv\",index=False)","metadata":{"execution":{"iopub.execute_input":"2021-10-15T19:28:48.575599Z","iopub.status.busy":"2021-10-15T19:28:48.574895Z","iopub.status.idle":"2021-10-15T19:28:48.874431Z","shell.execute_reply":"2021-10-15T19:28:48.873872Z","shell.execute_reply.started":"2021-10-15T19:26:25.323823Z"},"papermill":{"duration":0.326577,"end_time":"2021-10-15T19:28:48.874592","exception":false,"start_time":"2021-10-15T19:28:48.548015","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report,accuracy_score,make_scorer,confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import learning_curve\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.preprocessing import StandardScaler\n\nX=df_fs.drop([\"Label\"],axis=1)\ny=df_fs[\"Label\"]\n\nX=X.values\ny=y.values\n\nsc=StandardScaler()\nX=sc.fit_transform(X)\n\ndef draw_curve(train_sizes, train_scores, test_scores):\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    \n    plt.figure(figsize=(10,10))\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    plt.gca().invert_yaxis()\n    \n    # box-like grid\n    plt.grid()\n    \n    # plot the std deviation as a transparent range at each training set size\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    \n    # plot the average training and test score lines at each training set size\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n    \n    # sizes the window for readability and displays the plot\n    # shows error from 0 to 1.1\n    plt.legend(loc=\"best\")\n    plt.ylim(-.1,1.1)\n    plt.show()\n       \n\ndef classification_report_with_accuracy_score(y_true, y_pred):\n\n    print(classification_report(y_true, y_pred)) # print classification report\n    cm=confusion_matrix(y_true,y_pred)\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # For normalising the MAtrix for better visualisation.\n    plt.figure(figsize=(20,10))\n    plt.rc(\"font\",size=10)\n    sns.heatmap(cm,annot=True,fmt=\".2f\",cmap=\"viridis\")\n    plt.show()\n    return accuracy_score(y_true, y_pred) # return accuracy score\n\ndef fun_best(X,y):\n    models={\"XGB\":XGBClassifier(),\"LGBM\":LGBMClassifier(),\"GradientBoost\":GradientBoostingClassifier(),\"LDA\":LinearDiscriminantAnalysis(),\"RandomForest\":RandomForestClassifier()}\n    mean_score=[]\n    \n    for i,j in models.items():\n        model=j\n        score_model=cross_val_score(model,X,y,cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),scoring=make_scorer(classification_report_with_accuracy_score))\n        mean_score.append(score_model.mean())\n        train_sizes, train_scores, test_scores = learning_curve(model, X, y, n_jobs=-1, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n        draw_curve(train_sizes, train_scores, test_scores)\n        \n    result=dict(zip(models.keys(),mean_score))\n   \n    return result\n\nresult=fun_best(X,y)\nprint(\"For ANOVA Feature Selection:\")\nprint(result)","metadata":{"execution":{"iopub.execute_input":"2021-10-15T19:28:48.937929Z","iopub.status.busy":"2021-10-15T19:28:48.909123Z","iopub.status.idle":"2021-10-15T20:06:55.338766Z","shell.execute_reply":"2021-10-15T20:06:55.338235Z","shell.execute_reply.started":"2021-10-15T05:12:02.105009Z"},"papermill":{"duration":2286.451162,"end_time":"2021-10-15T20:06:55.338929","exception":false,"start_time":"2021-10-15T19:28:48.887767","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CHI2:","metadata":{}},{"cell_type":"code","source":"X=df.drop([\"Label\"],axis=1)\ny=df[\"Label\"]\ny=y.apply(lambda x:label.index(x))\n\nmn=MinMaxScaler()\nX_m=mn.fit_transform(X)\n\n# Create and fit selector\nselector = SelectKBest(chi2, k=50)\nselector.fit(X_m, y)\n# Get columns to keep and create new dataframe with those only\ncols = selector.get_support(indices=True)\nX_fs= X.iloc[:,cols]\n\ndf_fs=pd.concat([X_fs,y],axis=1)\n\ndf_fs.to_csv(\"CHI2_D2_C2.csv\",index=False)","metadata":{"execution":{"iopub.execute_input":"2021-10-15T20:06:56.100436Z","iopub.status.busy":"2021-10-15T20:06:56.099735Z","iopub.status.idle":"2021-10-15T20:06:56.479491Z","shell.execute_reply":"2021-10-15T20:06:56.480043Z"},"papermill":{"duration":0.765698,"end_time":"2021-10-15T20:06:56.480227","exception":false,"start_time":"2021-10-15T20:06:55.714529","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=df_fs.drop([\"Label\"],axis=1)\ny=df_fs[\"Label\"]\n\nX=X.values\ny=y.values\n\nsc=StandardScaler()\nX=sc.fit_transform(X)\n\ndef classification_report_with_accuracy_score(y_true, y_pred):\n\n    print(classification_report(y_true, y_pred)) # print classification report\n    cm=confusion_matrix(y_true,y_pred)\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # For normalising the MAtrix for better visualisation.\n    plt.figure(figsize=(20,10))\n    plt.rc(\"font\",size=10)\n    sns.heatmap(cm,annot=True,fmt=\".2f\",cmap=\"viridis\")\n    plt.show()\n    return accuracy_score(y_true, y_pred) # return accuracy score\n\ndef fun_best(X,y):\n    models={\"XGB\":XGBClassifier(),\"LGBM\":LGBMClassifier(),\"GradientBoost\":GradientBoostingClassifier(),\"LDA\":LinearDiscriminantAnalysis(),\"RandomForest\":RandomForestClassifier()}\n    mean_score=[]\n    \n    for i,j in models.items():\n        model=j\n        score_model=cross_val_score(model,X,y,cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),scoring=make_scorer(classification_report_with_accuracy_score))\n        mean_score.append(score_model.mean())\n        train_sizes, train_scores, test_scores = learning_curve(model, X, y, n_jobs=-1, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n        draw_curve(train_sizes, train_scores, test_scores)\n        \n    result=dict(zip(models.keys(),mean_score))\n   \n    return result\n\nresult=fun_best(X,y)\nprint(\"For CHI2 Feature Selection:\")\nprint(result)","metadata":{"execution":{"iopub.execute_input":"2021-10-15T20:06:57.250367Z","iopub.status.busy":"2021-10-15T20:06:57.249504Z","iopub.status.idle":"2021-10-15T20:59:02.956983Z","shell.execute_reply":"2021-10-15T20:59:02.95644Z"},"papermill":{"duration":3126.095076,"end_time":"2021-10-15T20:59:02.957158","exception":false,"start_time":"2021-10-15T20:06:56.862082","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### MI:","metadata":{}},{"cell_type":"code","source":"X=df.drop([\"Label\"],axis=1)\ny=df[\"Label\"]\ny=y.apply(lambda x:label.index(x))\n\n# Create and fit selector\nselector = SelectKBest(mutual_info_classif, k=50)\nselector.fit(X, y)\n# Get columns to keep and create new dataframe with those only\ncols = selector.get_support(indices=True)\nX_fs= X.iloc[:,cols]\n\ndf_fs=pd.concat([X_fs,y],axis=1)\n\ndf_fs.to_csv(\"MI_D2_C2.csv\",index=False)","metadata":{"execution":{"iopub.execute_input":"2021-10-15T20:59:04.473579Z","iopub.status.busy":"2021-10-15T20:59:04.457224Z","iopub.status.idle":"2021-10-15T20:59:27.179831Z","shell.execute_reply":"2021-10-15T20:59:27.180368Z"},"papermill":{"duration":23.483438,"end_time":"2021-10-15T20:59:27.18056","exception":false,"start_time":"2021-10-15T20:59:03.697122","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=df_fs.drop([\"Label\"],axis=1)\ny=df_fs[\"Label\"]\n\nX=X.values\ny=y.values\n\nsc=StandardScaler()\nX=sc.fit_transform(X)\n\ndef classification_report_with_accuracy_score(y_true, y_pred):\n\n    print(classification_report(y_true, y_pred)) # print classification report\n    cm=confusion_matrix(y_true,y_pred)\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # For normalising the MAtrix for better visualisation.\n    plt.figure(figsize=(20,10))\n    plt.rc(\"font\",size=10)\n    sns.heatmap(cm,annot=True,fmt=\".2f\",cmap=\"viridis\")\n    plt.show()\n    return accuracy_score(y_true, y_pred) # return accuracy score\n\ndef fun_best(X,y):\n    models={\"XGB\":XGBClassifier(),\"LGBM\":LGBMClassifier(),\"GradientBoost\":GradientBoostingClassifier(),\"LDA\":LinearDiscriminantAnalysis(),\"RandomForest\":RandomForestClassifier()}\n    mean_score=[]\n    \n    for i,j in models.items():\n        model=j\n        score_model=cross_val_score(model,X,y,cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),scoring=make_scorer(classification_report_with_accuracy_score))\n        mean_score.append(score_model.mean())\n        train_sizes, train_scores, test_scores = learning_curve(model, X, y, n_jobs=-1, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n        draw_curve(train_sizes, train_scores, test_scores)\n        \n    result=dict(zip(models.keys(),mean_score))\n   \n    return result\n\nresult=fun_best(X,y)\nprint(\"For MI Feature Selection:\")\nprint(result)","metadata":{"execution":{"iopub.execute_input":"2021-10-15T20:59:28.737841Z","iopub.status.busy":"2021-10-15T20:59:28.698588Z","iopub.status.idle":"2021-10-15T21:35:34.359909Z","shell.execute_reply":"2021-10-15T21:35:34.360436Z"},"papermill":{"duration":2166.428207,"end_time":"2021-10-15T21:35:34.360635","exception":false,"start_time":"2021-10-15T20:59:27.932428","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### RFE:","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/carlmcbrideellis/recursive-feature-elimination-rfe-example","metadata":{}},{"cell_type":"markdown","source":"Recursive feature elimination is an example of **backward feature elimination** in which we essentially first fit our model using all the features in a given set, then progressively one by one we remove the least significant features, each time re-fitting, until we are left with the desired number of features, which is set by the parameter **n_features_to_select**.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=df_fs.drop([\"Label\"],axis=1)\ny=df_fs[\"Label\"]\n\nX=X.values\ny=y.values\n\nsc=StandardScaler()\nX=sc.fit_transform(X)\n\ndef classification_report_with_accuracy_score(y_true, y_pred):\n\n    print(classification_report(y_true, y_pred)) # print classification report\n    cm=confusion_matrix(y_true,y_pred)\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # For normalising the MAtrix for better visualisation.\n    plt.figure(figsize=(20,10))\n    plt.rc(\"font\",size=10)\n    sns.heatmap(cm,annot=True,fmt=\".2f\",cmap=\"viridis\")\n    plt.show()\n    return accuracy_score(y_true, y_pred) # return accuracy score\n\ndef fun_best(X,y):\n    models={\"XGB\":XGBClassifier(),\"LGBM\":LGBMClassifier(),\"GradientBoost\":GradientBoostingClassifier(),\"LDA\":LinearDiscriminantAnalysis(),\"RandomForest\":RandomForestClassifier()}\n    mean_score=[]\n    \n    for i,j in models.items():\n        rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=50)\n        model=j\n        pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n        score_model=cross_val_score(pipeline,X,y,cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),scoring=make_scorer(classification_report_with_accuracy_score))\n        mean_score.append(score_model.mean())\n        train_sizes, train_scores, test_scores = learning_curve(model, X, y, n_jobs=-1, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n        draw_curve(train_sizes, train_scores, test_scores)\n        \n    result=dict(zip(models.keys(),mean_score))\n   \n    return result\n\nresult=fun_best(X,y)\nprint(\"For RFE Feature Selection:\")\nprint(result)","metadata":{},"execution_count":null,"outputs":[]}]}